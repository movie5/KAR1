{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Colab에서 돌아가기 위해 만들었습니다\n",
        "\n",
        "1. google mount는 너무 느려서 개인 repo에 파일을 올리고 clone했습니다.\n",
        "2. image에는 png 파일만 존재합니다\n",
        "3. kfold, ensemble, wb 는 https://www.kaggle.com/code/ayuraj/train-yolov5-cross-validation-ensemble-w-b 와 https://medium.com/@edusubin/k-fold-file-splitting-for-segmentation-networks-like-u-net-613ed013ec15 를 참고했습니다\n"
      ],
      "metadata": {
        "id": "qkanmzm6KeZf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://movie5: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@github.com/movie5/temporaryforcolab.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v13D-r3oAaKb",
        "outputId": "b2ee70e0-5735-4208-ff75-3aa26f95105b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'temporaryforcolab'...\n",
            "remote: Enumerating objects: 729, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 729 (delta 0), reused 3 (delta 0), pack-reused 726\u001b[K\n",
            "Receiving objects: 100% (729/729), 728.12 MiB | 17.57 MiB/s, done.\n",
            "Resolving deltas: 100% (54/54), done.\n",
            "Updating files: 100% (722/722), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# YOLOv5를 github에서 다운받아 사용합니다"
      ],
      "metadata": {
        "id": "-nXxxLXcKv7a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download YOLOv5\n",
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "# Install dependencies\n",
        "%pip install -qr yolov5/requirements.txt  # install dependencies"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaOJHvXyed1M",
        "outputId": "e5ebd728-31e7-45ac-e6e4-56468fa6b9c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'yolov5' already exists and is not an empty directory.\n",
            "/\n",
            "Setup complete. Using torch 2.0.1+cu118 (NVIDIA A100-SXM4-40GB)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd content/yolov5"
      ],
      "metadata": {
        "id": "8iFebqJD_H3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "QBsW_QRw_OIz",
        "outputId": "1aa54270-e95e-4b9f-e279-4d9fb194651f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bin\t\t\t    etc     media\t\t      root  tools\n",
            "boot\t\t\t    home    mnt\t\t\t      run   usr\n",
            "content\t\t\t    lib     NGC-DL-CONTAINER-LICENSE  sbin  var\n",
            "cuda-keyring_1.0-1_all.deb  lib32   opt\t\t\t      srv\n",
            "datalab\t\t\t    lib64   proc\t\t      sys\n",
            "dev\t\t\t    libx32  python-apt\t\t      tmp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install -qr /content/yolov5/requirements.txt # install dependencies"
      ],
      "metadata": {
        "id": "Ums7RFUK_BWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 학습상황을 파악하고 모델 파라미터를 보기 위해 wandb를 설치합니다.\n",
        "\n",
        "필수는 아니니 넘겨도 좋습니다."
      ],
      "metadata": {
        "id": "UFFbrpoTK4aR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install W&B\n",
        "!pip install -q --upgrade wandb\n",
        "# Login\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "BttJTcUmemG-",
        "outputId": "eb8e796a-3cbe-49e3-96d4-00b096e4a307"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.7/214.7 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Necessary/extra dependencies.\n",
        "import os\n",
        "import gc\n",
        "import cv2\n",
        "import glob\n",
        "import json\n",
        "import wandb\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "pd.set_option('mode.chained_assignment', None)\n",
        "from tqdm import tqdm\n",
        "from shutil import copyfile\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "#customize iPython writefile so we can write variables\n",
        "from IPython.core.magic import register_line_cell_magic\n",
        "\n",
        "@register_line_cell_magic\n",
        "def writetemplate(line, cell):\n",
        "    with open(line, 'w') as f:\n",
        "        f.write(cell.format(**globals()))"
      ],
      "metadata": {
        "id": "z9FM-NPRfAAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 변환해주는 코드입니다. 지우님의 코드입니다"
      ],
      "metadata": {
        "id": "I0SiVSNuLWwU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_coordinates(coords_str, image_width=1024, image_height=1024):\n",
        "  coords = coords_str.split(',')\n",
        "  x1, y1, x2, y2, x3, y3, x4, y4 = map(float, coords)\n",
        "  x = (x1 + x2 + x3 + x4) / 4\n",
        "  y = (y1 + y2 + y3 + y4) / 4\n",
        "  width = max(x1, x2, x3, x4) - min(x1, x2, x3, x4)\n",
        "  height = max(y1, y2, y3, y4) - min(y1, y2, y3, y4)\n",
        "\n",
        "  # 정규화된 좌표 계산(0-1사이)\n",
        "  x_normalized = x / image_width\n",
        "  y_normalized = y / image_height\n",
        "  width_normalized = width / image_width\n",
        "  height_normalized = height / image_height\n",
        "  return x_normalized, y_normalized, width_normalized, height_normalized"
      ],
      "metadata": {
        "id": "wFAyEEYpAqjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd temporaryforcolab"
      ],
      "metadata": {
        "id": "ZFOr1zfER3Ie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvnkbsE4XSeJ",
        "outputId": "064ec3b8-0ffd-4702-c1ea-eba3cf0943e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data  temporaryforcolab\tyolov5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "위 결과로 보이듯이 cd를 해도 이동이 안되서 이후 경로들은 절대경로입니다.\n",
        "\n",
        "아래는 create_yolo_annodations 함수를 csv를 거치지 않고 한번에 변환해서 txt로 만들어주는 코드입니다.\n",
        "\n",
        "저는 수동 KFOLD를 구현하기 위해 아직 train, validation split을 하지 않았습니다.\n",
        "\n",
        "yolo형식의 txt annotation 파일은 직접 생성한 train_labels_txt 폴더에 저장하게 됩니다."
      ],
      "metadata": {
        "id": "VOqB5GZaLk_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# kfold하기 위해 272개 파일의 확장자 전까지 명칭을 리스트에 저장하여 인덱스로 찾아서 사용합니다\n",
        "id_list = []\n",
        "\n",
        "# txt 파일을 저장할 폴더의 경로를 인수로 받습니다.\n",
        "def create_yolo_annotations(label_folder):\n",
        "  train_jsons = sorted(glob.glob('/content/temporaryforcolab/train_labels/*'))\n",
        "  for j in train_jsons:\n",
        "    #json 파일 하나를 엽니다\n",
        "    with open(j, 'r') as f:\n",
        "      # coord 리스트의 한 인덱스에 object 개수만큼 좌표가 들어갑니다\n",
        "      coord = []\n",
        "      tmp = json.load(f)\n",
        "      #먼저 txt파일의 이름과 경로를 만들어 줍니다.\n",
        "      txt_name = tmp['features'][0]['properties']['image_id'][:-3] + \"txt\"\n",
        "      txt_path = os.path.join(label_folder, txt_name)\n",
        "      #feature 안의 properties에서 object imcoords를 string으로 저장합니다\n",
        "      for o in tmp['features']:\n",
        "        object_imcoords = o['properties']['object_imcoords']\n",
        "        coord.append(object_imcoords)\n",
        "    #하나의 json파일에서 object_imcoords를 모두 불러오면 txt파일을 작성합니다\n",
        "    with open(txt_path, 'w') as t:\n",
        "      for r in coord:\n",
        "        # yolo data format에 맞추어 작성합니다.\n",
        "        x, y, width, height = convert_coordinates(r)\n",
        "        #하나의 클래스만 있기 때문에 0을 클래스로 두고 x,y, width, height를 추가합니다\n",
        "        t.write(f'0 {x:.6f} {y:.6f} {width:.6f} {height:.6f}\\n')\n",
        "\n",
        "    # 하나의 yolo txt가 작성되면 그 파일의 이름을 id list에 추가합니다.\n",
        "    id_list.append(tmp['features'][0]['properties']['image_id'][:-3])"
      ],
      "metadata": {
        "id": "Pny7yTqBBTRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## os.makedirs로 폴더를 생성했습니다."
      ],
      "metadata": {
        "id": "_kOGEyedNrEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/content/temporaryforcolab/train_label_txt')"
      ],
      "metadata": {
        "id": "iW02hCNhNdMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_yolo_annotations('/content/temporaryforcolab/train_label_txt')"
      ],
      "metadata": {
        "id": "A__ugziCSXyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래의 코드로 272개 모두 작성되었음을 확인했습니다."
      ],
      "metadata": {
        "id": "IDsHuxKnOBPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "initial_count = 0\n",
        "for path in pathlib.Path('temporaryforcolab/train_label_txt').iterdir():\n",
        "    if path.is_file():\n",
        "        initial_count += 1\n",
        "\n",
        "print(initial_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sexkBFry3HrI",
        "outputId": "b2ede51b-d828-4bc9-e1f8-8264abfdf001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "272\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 이 아래에는 학습을 위해 설치한 도구 입니다. 꼭 필요한 것은 아니므로 넘어가셔도 좋습니다."
      ],
      "metadata": {
        "id": "ax8_oCQIOG1G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ClearML"
      ],
      "metadata": {
        "id": "9OBdl2gZb0UG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Select YOLOv5 🚀 logger {run: 'auto'}\n",
        "logger = 'ClearML' #@param ['Comet', 'ClearML', 'TensorBoard']\n",
        "\n",
        "if logger == 'Comet':\n",
        "  %pip install -q comet_ml\n",
        "  import comet_ml; comet_ml.init()\n",
        "elif logger == 'ClearML':\n",
        "  %pip install -q clearml\n",
        "  import clearml; clearml.browser_login()\n",
        "elif logger == 'TensorBoard':\n",
        "  %load_ext tensorboard\n",
        "  %tensorboard --logdir runs/train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "lwq4FKpAbz0T",
        "outputId": "c90a515d-08a4-44cb-dd63-fd9fa6b8e034"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "                    window._ApiKey = new Promise((resolve, reject) => {\n",
              "                        const timeout = setTimeout(() => reject(\"Failed authenticating existing browser session\"), 5000)\n",
              "                        fetch(\"https://app.clear.ml/api/auth.login\", {\n",
              "                          method: 'GET',\n",
              "                          credentials: 'include'\n",
              "                        })\n",
              "                          .then((response) => resolve(response.json()))\n",
              "                          .then((json) => {\n",
              "                            clearTimeout(timeout);\n",
              "                          }).catch((err) => {\n",
              "                            clearTimeout(timeout);\n",
              "                            reject(err);\n",
              "                        });\n",
              "                    });\n",
              "                    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🤖 ClearML connected successfully - let's build something! 🚀\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 아래는 5 KFOLD cross validation을 구현하고자 수동으로 구현한 5개의 kfold train-validation 분리입니다"
      ],
      "metadata": {
        "id": "N-hxqKwfOYU8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "KFOLD for train/valid set!!\n",
        "\n",
        "---\n",
        "Source file structure\n",
        "\n",
        "->temporaryforcolab\n",
        "\n",
        "---->train_images\n",
        "\n",
        "---->train_label_txt\n",
        "\n",
        "---\n",
        "\n",
        "Destination file structure\n",
        "\n",
        "->content\n",
        "\n",
        "-->dataset_folds_0\n",
        "\n",
        "------------->train\n",
        "\n",
        "--------------------------->images\n",
        "\n",
        "--------------------------->labels\n",
        "\n",
        "------------->valid\n",
        "\n",
        "--------------------------->images\n",
        "\n",
        "--------------------------->labels\n",
        "\n",
        "-->dataset_folds_1\n",
        "\n",
        "------------->train\n",
        "\n",
        "--------------------------->images\n",
        "\n",
        "--------------------------->labels\n",
        "\n",
        "------------->valid\n",
        "\n",
        "--------------------------->images\n",
        "\n",
        "--------------------------->labels\n",
        "\n",
        "--> yolov5"
      ],
      "metadata": {
        "id": "w2BYb6xvtjR1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dir_names = ['dataset_folds_0','dataset_folds_1','dataset_folds_2','dataset_folds_3','dataset_folds_4']\n",
        "#validation_image_number = 54\n",
        "data_root = os.path.join(os.getcwd(),'temporaryforcolab')"
      ],
      "metadata": {
        "id": "ZjRa9_L3t0Qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_root"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "W8jC863S42kc",
        "outputId": "15633aa3-cd3e-4663-b164-4a5f0b1ac2f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/temporaryforcolab'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 272를 5-kfold 해보자.\n",
        "\n",
        "54개를 validation으로 둔다. 그러면 남은 218개는 train으로 두게 된다"
      ],
      "metadata": {
        "id": "St4Ehg0xwrBJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#이 코드는 id_list[0+i:54+i]가 잘 돌아가는 코드인지 확인하기 위한 것\n",
        "\"\"\"\n",
        "i = 0\n",
        "for _ in range(5):\n",
        "  test_files = id_list[0+i:54+i]\n",
        "  print(test_files[0], len(test_files), i)\n",
        "  i += 54"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Unb4ufXm39pa",
        "outputId": "86012c8d-8a18-43cf-d6d9-3cc297bc68c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OBJ00013_PS3_K3_NIA0078. 54 0\n",
            "OBJ03828_PS3_K3A_NIA0161. 54 54\n",
            "OBJ04437_PS3_K3A_NIA0291. 54 108\n",
            "OBJ04915_PS3_K3A_NIA0322. 54 162\n",
            "OBJ05395_PS3_K3A_NIA0347. 54 216\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "#복사될 원본 이미지와 라벨의 경로\n",
        "img_data_root = os.path.join(data_root,'train_images')\n",
        "label_data_root = os.path.join(data_root,'train_label_txt')\n",
        "\n",
        "for dir_name in dir_names:\n",
        "  print(dir_name)\n",
        "  #폴더 생성\n",
        "  os.makedirs(dir_name)\n",
        "\n",
        "  #making sub directoreis train and test\n",
        "  os.makedirs(os.path.join(os.getcwd(),dir_name,'train'))\n",
        "  os.makedirs(os.path.join(os.getcwd(),dir_name,'valid'))\n",
        "\n",
        "  #locating to the image and label directory\n",
        "  train_dir = os.path.join(os.getcwd(),dir_name,'train')\n",
        "  valid_dir = os.path.join(os.getcwd(),dir_name,'valid')\n",
        "\n",
        "  #making train and val sub-directories\n",
        "  os.makedirs(os.path.join(train_dir,'images'))\n",
        "  os.makedirs(os.path.join(train_dir,'labels'))\n",
        "  os.makedirs(os.path.join(valid_dir,'images'))\n",
        "  os.makedirs(os.path.join(valid_dir,'labels'))\n",
        "\n",
        "  #creating file names for validation\n",
        "\n",
        "  test_filenames =id_list[0+i:54+i]\n",
        "  for filename in test_filenames:\n",
        "    # validation 54개 만큼 인덱스 (0, 53), (54, 97) 가 dir0, dir1에 가게 된다\n",
        "    img_dest = os.path.join(os.getcwd(),dir_name,'valid', 'images')\n",
        "    label_dest = os.path.join(os.getcwd(),dir_name,'valid', 'labels')\n",
        "\n",
        "    #옮겨지게 될 file의 확장자를 포함한 경로\n",
        "    img_file_path = os.path.join(img_data_root,filename+'png')\n",
        "    label_file_path = os.path.join(label_data_root,filename+'txt')\n",
        "\n",
        "    # val image, label이 옮겨지게 된다.\n",
        "    shutil.copy(img_file_path,img_dest)\n",
        "    shutil.copy(label_file_path,label_dest)\n",
        "\n",
        "  #saving files for training(val에 들어가지 않은 파일들)\n",
        "  for other_filename in id_list:\n",
        "    if other_filename in test_filenames:\n",
        "      continue\n",
        "    else:\n",
        "      # train 272-54 = 216개 만큼 인덱스 (54, 271), (0~53, 98~271) 가 dir0, dir1에 가게 된다\n",
        "      img_dest = os.path.join(os.getcwd(),dir_name,'train', 'images')\n",
        "      label_dest = os.path.join(os.getcwd(),dir_name,'train', 'labels')\n",
        "\n",
        "      img_file_path = os.path.join(img_data_root,other_filename + 'png')\n",
        "      label_file_path = os.path.join(label_data_root,other_filename+'txt')\n",
        "\n",
        "      shutil.copy(img_file_path,img_dest)\n",
        "      shutil.copy(label_file_path,label_dest)\n",
        "  #한 datafolder에 가게 되면 다음 54개에 대해서 수행한다\n",
        "  i+=54"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3lbwLfyuKvl",
        "outputId": "cbd27953-98ad-4b91-e014-17fccb25a9f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset_folds_0\n",
            "dataset_folds_1\n",
            "dataset_folds_2\n",
            "dataset_folds_3\n",
            "dataset_folds_4\n",
            "dataset_folds_5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "잘 입력이 되었나 확인해보는 코드 54개로 잘 분배되었음을 알 수 있다."
      ],
      "metadata": {
        "id": "LBdcIDwmWmo1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "initial_count = 0\n",
        "for path in pathlib.Path('/content/dataset_folds_1/images/val').iterdir():\n",
        "    if path.is_file():\n",
        "        initial_count += 1\n",
        "        print(path)\n",
        "\n",
        "print(initial_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3dcjKOM1Hmp",
        "outputId": "a638fa74-d12a-4b88-97f2-77ef956a1c88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/dataset_folds_1/images/val/OBJ04042_PS3_K3A_NIA0170.png\n",
            "/content/dataset_folds_1/images/val/OBJ04135_PS3_K3A_NIA0177.png\n",
            "/content/dataset_folds_1/images/val/OBJ04153_PS3_K3A_NIA0179.png\n",
            "/content/dataset_folds_1/images/val/OBJ03945_PS3_K3A_NIA0166.png\n",
            "/content/dataset_folds_1/images/val/OBJ04026_PS3_K3A_NIA0169.png\n",
            "/content/dataset_folds_1/images/val/OBJ04351_PS3_K3A_NIA0283.png\n",
            "/content/dataset_folds_1/images/val/OBJ04407_PS3_K3A_NIA0289.png\n",
            "/content/dataset_folds_1/images/val/OBJ04370_PS3_K3A_NIA0285.png\n",
            "/content/dataset_folds_1/images/val/OBJ04361_PS3_K3A_NIA0285.png\n",
            "/content/dataset_folds_1/images/val/OBJ04088_PS3_K3A_NIA0173.png\n",
            "/content/dataset_folds_1/images/val/OBJ04028_PS3_K3A_NIA0169.png\n",
            "/content/dataset_folds_1/images/val/OBJ04382_PS3_K3A_NIA0287.png\n",
            "/content/dataset_folds_1/images/val/OBJ04376_PS3_K3A_NIA0286.png\n",
            "/content/dataset_folds_1/images/val/OBJ04093_PS3_K3A_NIA0174.png\n",
            "/content/dataset_folds_1/images/val/OBJ04038_PS3_K3A_NIA0170.png\n",
            "/content/dataset_folds_1/images/val/OBJ04123_PS3_K3A_NIA0175.png\n",
            "/content/dataset_folds_1/images/val/OBJ03967_PS3_K3A_NIA0166.png\n",
            "/content/dataset_folds_1/images/val/OBJ04360_PS3_K3A_NIA0285.png\n",
            "/content/dataset_folds_1/images/val/OBJ04053_PS3_K3A_NIA0170.png\n",
            "/content/dataset_folds_1/images/val/OBJ04125_PS3_K3A_NIA0176.png\n",
            "/content/dataset_folds_1/images/val/OBJ04144_PS3_K3A_NIA0178.png\n",
            "/content/dataset_folds_1/images/val/OBJ03828_PS3_K3A_NIA0161.png\n",
            "/content/dataset_folds_1/images/val/OBJ03963_PS3_K3A_NIA0166.png\n",
            "/content/dataset_folds_1/images/val/OBJ04422_PS3_K3A_NIA0290.png\n",
            "/content/dataset_folds_1/images/val/OBJ04386_PS3_K3A_NIA0287.png\n",
            "/content/dataset_folds_1/images/val/OBJ03947_PS3_K3A_NIA0166.png\n",
            "/content/dataset_folds_1/images/val/OBJ04064_PS3_K3A_NIA0171.png\n",
            "/content/dataset_folds_1/images/val/OBJ03836_PS3_K3A_NIA0161.png\n",
            "/content/dataset_folds_1/images/val/OBJ03840_PS3_K3A_NIA0161.png\n",
            "/content/dataset_folds_1/images/val/OBJ04152_PS3_K3A_NIA0179.png\n",
            "/content/dataset_folds_1/images/val/OBJ04393_PS3_K3A_NIA0288.png\n",
            "/content/dataset_folds_1/images/val/OBJ04059_PS3_K3A_NIA0171.png\n",
            "/content/dataset_folds_1/images/val/OBJ04431_PS3_K3A_NIA0290.png\n",
            "/content/dataset_folds_1/images/val/OBJ04022_PS3_K3A_NIA0169.png\n",
            "/content/dataset_folds_1/images/val/OBJ03885_PS3_K3A_NIA0164.png\n",
            "/content/dataset_folds_1/images/val/OBJ04356_PS3_K3A_NIA0284.png\n",
            "/content/dataset_folds_1/images/val/OBJ03864_PS3_K3A_NIA0162.png\n",
            "/content/dataset_folds_1/images/val/OBJ03964_PS3_K3A_NIA0166.png\n",
            "/content/dataset_folds_1/images/val/OBJ03950_PS3_K3A_NIA0166.png\n",
            "/content/dataset_folds_1/images/val/OBJ04238_PS3_K3_NIA0278.png\n",
            "/content/dataset_folds_1/images/val/OBJ04323_PS3_K3_NIA0280.png\n",
            "/content/dataset_folds_1/images/val/OBJ03970_PS3_K3A_NIA0166.png\n",
            "/content/dataset_folds_1/images/val/OBJ04397_PS3_K3A_NIA0289.png\n",
            "/content/dataset_folds_1/images/val/OBJ04070_PS3_K3A_NIA0171.png\n",
            "/content/dataset_folds_1/images/val/OBJ04052_PS3_K3A_NIA0170.png\n",
            "/content/dataset_folds_1/images/val/OBJ03932_PS3_K3A_NIA0166.png\n",
            "/content/dataset_folds_1/images/val/OBJ04396_PS3_K3A_NIA0289.png\n",
            "/content/dataset_folds_1/images/val/OBJ04186_PS3_K3A_NIA0180.png\n",
            "/content/dataset_folds_1/images/val/OBJ04019_PS3_K3A_NIA0169.png\n",
            "/content/dataset_folds_1/images/val/OBJ04419_PS3_K3A_NIA0289.png\n",
            "/content/dataset_folds_1/images/val/OBJ04066_PS3_K3A_NIA0171.png\n",
            "/content/dataset_folds_1/images/val/OBJ03941_PS3_K3A_NIA0166.png\n",
            "/content/dataset_folds_1/images/val/OBJ04018_PS3_K3A_NIA0169.png\n",
            "/content/dataset_folds_1/images/val/OBJ04143_PS3_K3A_NIA0178.png\n",
            "54\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🍜 Create .YAML file\n",
        "###The data.yaml, is the dataset configuration file that defines\n",
        "\n",
        "1. an \"optional\" download command/URL for auto-downloading,\n",
        "2. a path to a directory of training images (or path to a *.txt file with a list of training images),\n",
        "3. a path to a directory of validation images (or path to a *.txt file with a list of validation images),\n",
        "the number of classes,\n",
        "4. a list of class names.\n",
        "\n",
        "<tip>\n",
        " 📍 Important: In this competition, each image can either belong to opacity or none image-level labels. That's why I have used the number of classes, nc to be 2. YOLOv5 automatically handles the images without any bounding box coordinates.\n",
        "\n",
        "📍 Note: The data.yaml is created in the yolov5/data directory as required.\n",
        "</tip>"
      ],
      "metadata": {
        "id": "q7FXQoFZWueU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create .yaml file\n",
        "import yaml\n",
        "NUM_FOLD = 5\n",
        "for fold in range(NUM_FOLD):\n",
        "    data_yaml = dict(\n",
        "        train = f'../dataset_folds_{fold}/train',\n",
        "        val = f'../dataset_folds_{fold}/valid',\n",
        "        nc = 1,\n",
        "        names = ['container']\n",
        "    )\n",
        "\n",
        "    # Note that I am creating the file in the yolov5/data/ directory.\n",
        "    with open(f'yolov5/data/data_fold_{fold}.yaml', 'w') as outfile:\n",
        "        yaml.dump(data_yaml, outfile, default_flow_style=True)\n",
        "\n",
        "%cat yolov5/data/data_fold_0.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E65qpL6CXNKk",
        "outputId": "8a68e190-b65d-4f44-bd88-30762c94c4ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{names: [container], nc: 1, train: ../dataset_folds_0/images/train, val: ../dataset_folds_0/images/valid}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "cd가 안되서 절대경로를 씁니다....ㅠㅠㅠ\n",
        "\n",
        "--img {IMG_SIZE} \\ # Input image size = 640\n",
        "\n",
        "--batch {BATCH_SIZE} \\ # Batch size = 16\n",
        "\n",
        "--epochs {EPOCHS} \\ # Number of epochs = 7\n",
        "\n",
        "--data data.yaml \\ # Configuration file\n",
        "\n",
        "--weights '' \\ # We don't use pretrained\n",
        "\n",
        "--seed = {SEED} # Seed는 77로 fix\n",
        "\n",
        "--save_period 10 \\ # Save model after interval\n",
        "\n",
        "--project kaggle-siim-covid # W&B project name"
      ],
      "metadata": {
        "id": "vM9SX-QRY3h5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U ultralytics"
      ],
      "metadata": {
        "id": "edRSU4XgBbhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "def main():\n",
        "    model = YOLO(\"ultralytics/ultralytics/cfg/models/v5/yolov5.yaml\")\n",
        "    model.info()\n",
        "    model.train(data=\"C://Users/laboratory/repository/oiltank/oiltank_dataset/data.yaml\", epochs=500)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "XUL_XRixCdc3",
        "outputId": "26878ef1-8e42-447c-80ad-a56392e84311",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-93-2eaaae1297c2>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-93-2eaaae1297c2>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ultralytics/ultralytics/cfg/models/v5/yolov5.yaml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C://Users/laboratory/repository/oiltank/oiltank_dataset/data.yaml\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, task)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_suffix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.pt'\u001b[0m  \u001b[0;31m# add suffix, i.e. yolov8n -> yolov8n.pt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msuffix\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'.yaml'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36m_new\u001b[0;34m(self, cfg, task, verbose)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0mverbose\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdisplay\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0minfo\u001b[0m \u001b[0mon\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \"\"\"\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mcfg_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myaml_model_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mguess_model_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36myaml_model_load\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m     \u001b[0munified_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'(\\d+)([nslmx])(.+)?$'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mr'\\1\\3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# i.e. yolov8x.yaml -> yolov8.yaml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m     \u001b[0myaml_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_yaml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munified_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhard\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcheck_yaml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myaml_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myaml_file\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# model dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'scale'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mguess_model_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/utils/checks.py\u001b[0m in \u001b[0;36mcheck_yaml\u001b[0;34m(file, suffix, hard)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheck_yaml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.yaml'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.yml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhard\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;34m\"\"\"Search/download YAML file (if necessary) and return path, checking suffix.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcheck_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhard\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/utils/checks.py\u001b[0m in \u001b[0;36mcheck_file\u001b[0;34m(file, suffix, download, hard)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mROOT\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'cfg'\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'**'\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# find file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhard\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"'{file}' does not exist\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhard\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Multiple files match '{file}', specify exact path: {files}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: 'ultralytics/ultralytics/cfg/models/v5/yolov5.yaml' does not exist"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Model\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=False)\n"
      ],
      "metadata": {
        "id": "QZSKHg9TBjCG",
        "outputId": "487389ef-18b6-4a42-f63b-2a96b44b5ab3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/hub.py:286: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
            "  warnings.warn(\n",
            "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "WARNING ⚠️ 'ultralytics.yolo.v8' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.models.yolo' instead.\n",
            "WARNING ⚠️ 'ultralytics.yolo.utils' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.utils' instead.\n",
            "Note this warning may be related to loading older models. You can update your model to current structure with:\n",
            "    import torch\n",
            "    ckpt = torch.load(\"model.pt\")  # applies to both official and custom models\n",
            "    torch.save(ckpt, \"updated-model.pt\")\n",
            "\n",
            "YOLOv5 🚀 2023-7-24 Python-3.10.6 torch-2.0.1+cu118 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n",
            "\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1    229245  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "YOLOv5s summary: 214 layers, 7235389 parameters, 7235389 gradients, 16.6 GFLOPs\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.train(data=\"/content/yolov5/data/data_fold_4.yaml\", epochs=500)"
      ],
      "metadata": {
        "id": "loLVvB-gC9X6",
        "outputId": "6e05f900-8a59-4a4c-f1ad-3eaebf6b8a11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-94-3f02994df23e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/yolov5/data/data_fold_4.yaml\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: Module.train() got an unexpected keyword argument 'data'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "def main():\n",
        "    model = YOLO(\"ultralytics/ultralytics/cfg/models/v5/yolov5.yaml\")\n",
        "    model.info()\n",
        "    model.train(data=\"/content/yolov5/data/data_fold_4.yaml\", epochs=100)"
      ],
      "metadata": {
        "id": "RtxEVOf-BO_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/yolov5/train.py  --img 620 --batch 32 --epochs 200 --data /content/yolov5/data/data_fold_2.yaml --weights '' --cfg /content/yolov5/models/yolov5s.yaml --project yolov5-con --name yolov5-e-200-img-620-fold-2 --cache"
      ],
      "metadata": {
        "id": "_0KwPVd1_pXP",
        "outputId": "eda54474-7f98-42d2-f0a9-d589b81f058f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING ⚠️ 'ultralytics.yolo.v8' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.models.yolo' instead.\n",
            "WARNING ⚠️ 'ultralytics.yolo.utils' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.utils' instead.\n",
            "Note this warning may be related to loading older models. You can update your model to current structure with:\n",
            "    import torch\n",
            "    ckpt = torch.load(\"model.pt\")  # applies to both official and custom models\n",
            "    torch.save(ckpt, \"updated-model.pt\")\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ⚠️ wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33moyh5800\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=, cfg=/content/yolov5/models/yolov5s.yaml, data=/content/yolov5/data/data_fold_2.yaml, hyp=content/yolov5/data/hyps/hyp.scratch-low.yaml, epochs=200, batch_size=32, imgsz=620, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5-con, name=yolov5-e-200-img-620-fold-2, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v7.0-196-gacdf73b Python-3.10.6 torch-2.0.1+cu118 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov5-con', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/wandb/run-20230724_225604-tu7v4o1k\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33myolov5-e-200-img-620-fold-2\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/oyh5800/yolov5-con\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/oyh5800/yolov5-con/runs/tu7v4o1k\u001b[0m\n",
            "ClearML Task: created new task id=8d7c537c76164d3aa550c025dffc926a\n",
            "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
            "ClearML results page: https://app.clear.ml/projects/42ab783900fd4bc29b4cc94bf6770d84/experiments/8d7c537c76164d3aa550c025dffc926a/output/log\n",
            "\n",
            "Dataset not found ⚠️, missing paths ['/content/dataset_folds_2/valid']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov5/train.py\", line 647, in <module>\n",
            "    main(opt)\n",
            "  File \"/content/yolov5/train.py\", line 536, in main\n",
            "    train(opt.hyp, opt, device, callbacks)\n",
            "  File \"/content/yolov5/train.py\", line 117, in train\n",
            "    data_dict = data_dict or check_dataset(data)  # check if None\n",
            "  File \"/content/yolov5/utils/general.py\", line 517, in check_dataset\n",
            "    raise Exception('Dataset not found ❌')\n",
            "Exception: Dataset not found ❌\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/yolov5/train.py  --img 640 --batch 32 --epochs 100 --data /content/yolov5/data/data_fold_3.yaml --weights '' --cfg /content/yolov5/models/yolov5s.yaml --project yolov5-con --name yolov5-e-7-img-640-fold-3 --cache"
      ],
      "metadata": {
        "id": "V2C-a-dUEqkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "  print('FOLD NUMBER: ', fold)\n",
        "\n",
        "  print('###########################################################################################\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Yt354YJZ4Nx",
        "outputId": "5d2b1696-0c35-4ead-f7e7-ae46c3b4b9c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD NUMBER:  1\n",
            "WARNING ⚠️ 'ultralytics.yolo.v8' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.models.yolo' instead.\n",
            "WARNING ⚠️ 'ultralytics.yolo.utils' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.utils' instead.\n",
            "Note this warning may be related to loading older models. You can update your model to current structure with:\n",
            "    import torch\n",
            "    ckpt = torch.load(\"model.pt\")  # applies to both official and custom models\n",
            "    torch.save(ckpt, \"updated-model.pt\")\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ⚠️ wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33moyh5800\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=, cfg=/content/yolov5/models/yolov5s.yaml, data=/content/yolov5/data/data_fold_1.yaml, hyp=yolov5/data/hyps/hyp.scratch-low.yaml, epochs=5, batch_size=32, imgsz=256, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5-container-folds, name=yolov5-e-7-img-640-fold-1, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v7.0-196-gacdf73b Python-3.10.6 torch-2.0.1+cu118 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov5-container-folds', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20230724_221022-bqavb85g\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33myolov5-e-7-img-640-fold-1\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/oyh5800/yolov5-container-folds\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/oyh5800/yolov5-container-folds/runs/bqavb85g\u001b[0m\n",
            "ClearML Task: created new task id=175c37b4e7d942cea113089c9e8a4880\n",
            "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
            "ClearML results page: https://app.clear.ml/projects/cd2916daae6a43339843d1e80c424e51/experiments/175c37b4e7d942cea113089c9e8a4880/output/log\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "YOLOv5s summary: 214 layers, 7022326 parameters, 7022326 gradients, 15.9 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset_folds_1/train/labels.cache... 218 images, 0 backgrounds, 0 corrupt: 100% 218/218 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB ram): 100% 218/218 [00:01<00:00, 216.31it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset_folds_1/valid/labels.cache... 54 images, 0 backgrounds, 0 corrupt: 100% 54/54 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram): 100% 54/54 [00:00<00:00, 86.19it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m1.22 anchors/target, 0.697 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mWARNING ⚠️ Extremely small objects found: 2330 of 7586 labels are <3 pixels in size\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 7512 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.7698: 100% 1000/1000 [00:01<00:00, 949.38it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 0.9993 best possible recall, 5.75 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=256, metric_all=0.370/0.767-mean/best, past_thr=0.508-mean: 3,3, 6,3, 3,6, 6,5, 7,7, 10,10, 19,18, 34,15, 17,102\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to yolov5-container-folds/yolov5-e-7-img-640-fold-12/labels.jpg... \n",
            "Image sizes 256 train, 256 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1myolov5-container-folds/yolov5-e-7-img-640-fold-12\u001b[0m\n",
            "Starting training for 5 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/4      1.41G     0.1823   0.006528          0        964        256: 100% 7/7 [00:10<00:00,  1.53s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.18it/s]\n",
            "                   all         54       2567   0.000556    0.00351   0.000281   6.86e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/4      1.41G     0.1782   0.007082          0        915        256: 100% 7/7 [00:00<00:00, 10.19it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.06s/it]\n",
            "                   all         54       2567   0.000679    0.00429   0.000343   7.82e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/4      1.41G     0.1748   0.007339          0       1133        256: 100% 7/7 [00:00<00:00, 13.61it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.42it/s]\n",
            "                   all         54       2567   0.000679    0.00429   0.000344   5.64e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/4      1.41G     0.1723   0.007229          0        541        256: 100% 7/7 [00:00<00:00, 12.90it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.24it/s]\n",
            "                   all         54       2567   0.000556    0.00351   0.000288   4.55e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/4      1.41G     0.1688   0.009027          0        674        256: 100% 7/7 [00:00<00:00, 12.89it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.32it/s]\n",
            "                   all         54       2567   0.000432    0.00273   0.000238   3.64e-05\n",
            "\n",
            "5 epochs completed in 0.005 hours.\n",
            "Optimizer stripped from yolov5-container-folds/yolov5-e-7-img-640-fold-12/weights/last.pt, 14.3MB\n",
            "Optimizer stripped from yolov5-container-folds/yolov5-e-7-img-640-fold-12/weights/best.pt, 14.3MB\n",
            "\n",
            "Validating yolov5-container-folds/yolov5-e-7-img-640-fold-12/weights/best.pt...\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.29it/s]\n",
            "                   all         54       2567   0.000679    0.00429   0.000343   7.82e-05\n",
            "Results saved to \u001b[1myolov5-container-folds/yolov5-e-7-img-640-fold-12\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▄██▄▁█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▆█▄▃▁█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▅██▅▁█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▅██▅▁█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▆▄▃▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss ▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▁▃▃▃█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss █▆▄▂▁▆\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▃▄▆█▃\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▆▅▃▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▆█▇▂\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▁▆█▇▂\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.00034\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 8e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.00068\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.00429\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.00034\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 8e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.00068\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.00429\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.1688\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.00903\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.17751\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.00577\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.06671\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00071\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00071\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33myolov5-e-7-img-640-fold-1\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/oyh5800/yolov5-container-folds/runs/bqavb85g\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 13 media file(s), 1 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230724_221022-bqavb85g/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ⚠️ wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
            "###########################################################################################\n",
            "\n",
            "FOLD NUMBER:  2\n",
            "WARNING ⚠️ 'ultralytics.yolo.v8' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.models.yolo' instead.\n",
            "WARNING ⚠️ 'ultralytics.yolo.utils' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.utils' instead.\n",
            "Note this warning may be related to loading older models. You can update your model to current structure with:\n",
            "    import torch\n",
            "    ckpt = torch.load(\"model.pt\")  # applies to both official and custom models\n",
            "    torch.save(ckpt, \"updated-model.pt\")\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ⚠️ wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33moyh5800\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=, cfg=/content/yolov5/models/yolov5s.yaml, data=/content/yolov5/data/data_fold_2.yaml, hyp=yolov5/data/hyps/hyp.scratch-low.yaml, epochs=5, batch_size=32, imgsz=256, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5-container-folds, name=yolov5-e-7-img-640-fold-2, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v7.0-196-gacdf73b Python-3.10.6 torch-2.0.1+cu118 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov5-container-folds', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20230724_221223-lxsvlflx\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33myolov5-e-7-img-640-fold-2\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/oyh5800/yolov5-container-folds\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/oyh5800/yolov5-container-folds/runs/lxsvlflx\u001b[0m\n",
            "ClearML Task: created new task id=aceaa9da15ab43f6944299c3ae7b7da8\n",
            "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
            "ClearML results page: https://app.clear.ml/projects/cd2916daae6a43339843d1e80c424e51/experiments/aceaa9da15ab43f6944299c3ae7b7da8/output/log\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "YOLOv5s summary: 214 layers, 7022326 parameters, 7022326 gradients, 15.9 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset_folds_2/train/labels.cache... 218 images, 0 backgrounds, 0 corrupt: 100% 218/218 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB ram): 100% 218/218 [00:01<00:00, 207.14it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset_folds_2/valid/labels.cache... 54 images, 0 backgrounds, 0 corrupt: 100% 54/54 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram): 100% 54/54 [00:00<00:00, 81.39it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m1.18 anchors/target, 0.666 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mWARNING ⚠️ Extremely small objects found: 2716 of 7998 labels are <3 pixels in size\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 7890 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.7545: 100% 1000/1000 [00:00<00:00, 1101.38it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 0.9982 best possible recall, 5.20 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=256, metric_all=0.342/0.750-mean/best, past_thr=0.505-mean: 3,3, 5,2, 3,6, 6,5, 8,8, 11,11, 21,31, 44,16, 15,102\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to yolov5-container-folds/yolov5-e-7-img-640-fold-22/labels.jpg... \n",
            "Image sizes 256 train, 256 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1myolov5-container-folds/yolov5-e-7-img-640-fold-22\u001b[0m\n",
            "Starting training for 5 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/4      1.41G     0.1773   0.006785          0        798        256: 100% 7/7 [00:12<00:00,  1.85s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.21it/s]\n",
            "                   all         54       2155   0.000247    0.00186    0.00013   3.22e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/4      1.41G     0.1729   0.007469          0        832        256: 100% 7/7 [00:00<00:00, 11.15it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.38it/s]\n",
            "                   all         54       2155   0.000185    0.00139    9.9e-05   1.61e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/4      1.41G     0.1717   0.007654          0       1031        256: 100% 7/7 [00:00<00:00, 11.15it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.31it/s]\n",
            "                   all         54       2155   0.000185    0.00139   9.27e-05   1.55e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/4      1.41G     0.1698   0.007484          0        407        256: 100% 7/7 [00:00<00:00, 11.99it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.12it/s]\n",
            "                   all         54       2155   0.000123   0.000928   6.19e-05   1.86e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/4      1.41G     0.1661   0.009146          0        757        256: 100% 7/7 [00:00<00:00, 11.80it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.44it/s]\n",
            "                   all         54       2155   0.000123   0.000928   6.18e-05   2.16e-05\n",
            "\n",
            "5 epochs completed in 0.006 hours.\n",
            "Optimizer stripped from yolov5-container-folds/yolov5-e-7-img-640-fold-22/weights/last.pt, 14.3MB\n",
            "Optimizer stripped from yolov5-container-folds/yolov5-e-7-img-640-fold-22/weights/best.pt, 14.3MB\n",
            "\n",
            "Validating yolov5-container-folds/yolov5-e-7-img-640-fold-22/weights/best.pt...\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.31it/s]\n",
            "                   all         54       2155   0.000247    0.00186    0.00013   3.22e-05\n",
            "Results saved to \u001b[1myolov5-container-folds/yolov5-e-7-img-640-fold-22\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 █▅▄▁▁█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 █▁▁▂▄█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision █▅▅▁▁█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall █▅▅▁▁█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▅▃▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss ▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▁▃▄▃█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss █▆▄▃▁█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▃▄▆█▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▆▅▃▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▆█▇▂\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▁▆█▇▂\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.00013\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 3e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.00025\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.00186\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.00013\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 3e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.00025\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.00186\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.1661\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.00915\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.1762\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.00477\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.06671\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00071\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00071\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33myolov5-e-7-img-640-fold-2\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/oyh5800/yolov5-container-folds/runs/lxsvlflx\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 13 media file(s), 1 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230724_221223-lxsvlflx/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ⚠️ wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov5/train.py\", line 647, in <module>\n",
            "    main(opt)\n",
            "  File \"/content/yolov5/train.py\", line 536, in main\n",
            "    train(opt.hyp, opt, device, callbacks)\n",
            "  File \"/content/yolov5/train.py\", line 436, in train\n",
            "    callbacks.run('on_train_end', last, best, epoch, results)\n",
            "  File \"/content/yolov5/utils/callbacks.py\", line 76, in run\n",
            "    logger['callback'](*args, **kwargs)\n",
            "  File \"/content/yolov5/utils/loggers/__init__.py\", line 292, in on_train_end\n",
            "    self.clearml.task.update_output_model(model_path=str(best if best.exists() else last),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/clearml/backend_interface/task/task.py\", line 1011, in update_output_model\n",
            "    output_model.connect(task=self, name=name)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/clearml/model.py\", line 2147, in connect\n",
            "    task.set_model_label_enumeration(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/clearml/task.py\", line 2330, in set_model_label_enumeration\n",
            "    super(Task, self).set_model_label_enumeration(enumeration=enumeration)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/clearml/backend_interface/task/task.py\", line 1399, in set_model_label_enumeration\n",
            "    self._edit(execution=execution)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/clearml/backend_interface/task/task.py\", line 2577, in _edit\n",
            "    res = self.send(tasks.EditRequest(task=self.id, force=True, **kwargs), raise_on_errors=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/clearml/backend_interface/base.py\", line 109, in send\n",
            "    return self._send(session=self.session, req=req, ignore_errors=ignore_errors, raise_on_errors=raise_on_errors,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/clearml/backend_interface/base.py\", line 60, in _send\n",
            "    res = session.send(req, async_enable=async_enable)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/clearml/backend_api/session/session.py\", line 634, in send\n",
            "    res = self.send_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/clearml/backend_api/session/session.py\", line 486, in send_request\n",
            "    return self._send_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/clearml/backend_api/session/session.py\", line 408, in _send_request\n",
            "    res = self.__http_session.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/sessions.py\", line 529, in request\n",
            "    resp = self.send(prep, **send_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/clearml/backend_api/utils.py\", line 85, in send\n",
            "    return super(SessionWithTimeout, self).send(request, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/sessions.py\", line 645, in send\n",
            "    r = adapter.send(request, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/adapters.py\", line 440, in send\n",
            "    resp = conn.urlopen(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 714, in urlopen\n",
            "    httplib_response = self._make_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 466, in _make_request\n",
            "    six.raise_from(e, None)\n",
            "  File \"<string>\", line 3, in raise_from\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 461, in _make_request\n",
            "    httplib_response = conn.getresponse()\n",
            "  File \"/usr/lib/python3.10/http/client.py\", line 1374, in getresponse\n",
            "    response.begin()\n",
            "  File \"/usr/lib/python3.10/http/client.py\", line 318, in begin\n",
            "    version, status, reason = self._read_status()\n",
            "  File \"/usr/lib/python3.10/http/client.py\", line 279, in _read_status\n",
            "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
            "  File \"/usr/lib/python3.10/socket.py\", line 705, in readinto\n",
            "    return self._sock.recv_into(b)\n",
            "  File \"/usr/lib/python3.10/ssl.py\", line 1274, in recv_into\n",
            "    return self.read(nbytes, buffer)\n",
            "  File \"/usr/lib/python3.10/ssl.py\", line 1130, in read\n",
            "    return self._sslobj.read(len, buffer)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/clearml/task.py\", line 4239, in signal_handler\n",
            "    return org_handler if not callable(org_handler) else org_handler(sig, frame)\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "###########################################################################################\n",
            "\n",
            "FOLD NUMBER:  3\n",
            "WARNING ⚠️ 'ultralytics.yolo.v8' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.models.yolo' instead.\n",
            "WARNING ⚠️ 'ultralytics.yolo.utils' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.utils' instead.\n",
            "Note this warning may be related to loading older models. You can update your model to current structure with:\n",
            "    import torch\n",
            "    ckpt = torch.load(\"model.pt\")  # applies to both official and custom models\n",
            "    torch.save(ckpt, \"updated-model.pt\")\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ⚠️ wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33moyh5800\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=, cfg=/content/yolov5/models/yolov5s.yaml, data=/content/yolov5/data/data_fold_3.yaml, hyp=yolov5/data/hyps/hyp.scratch-low.yaml, epochs=5, batch_size=32, imgsz=256, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5-container-folds, name=yolov5-e-7-img-640-fold-3, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v7.0-196-gacdf73b Python-3.10.6 torch-2.0.1+cu118 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov5-container-folds', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20230724_221405-t82ggx5t\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33myolov5-e-7-img-640-fold-3\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/oyh5800/yolov5-container-folds\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/oyh5800/yolov5-container-folds/runs/t82ggx5t\u001b[0m\n",
            "ClearML Task: created new task id=3564129ad4e049ec89afe9e74ee6f6fd\n",
            "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
            "ClearML results page: https://app.clear.ml/projects/cd2916daae6a43339843d1e80c424e51/experiments/3564129ad4e049ec89afe9e74ee6f6fd/output/log\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "YOLOv5s summary: 214 layers, 7022326 parameters, 7022326 gradients, 15.9 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset_folds_3/train/labels.cache... 218 images, 0 backgrounds, 0 corrupt: 100% 218/218 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB ram): 100% 218/218 [00:00<00:00, 222.58it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset_folds_3/valid/labels.cache... 54 images, 0 backgrounds, 0 corrupt: 100% 54/54 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram): 100% 54/54 [00:00<00:00, 92.49it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m1.15 anchors/target, 0.674 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mWARNING ⚠️ Extremely small objects found: 3060 of 9130 labels are <3 pixels in size\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 8999 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.7652: 100% 1000/1000 [00:01<00:00, 902.47it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 0.9980 best possible recall, 6.00 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=256, metric_all=0.382/0.761-mean/best, past_thr=0.506-mean: 3,3, 6,3, 3,6, 6,5, 8,8, 12,5, 12,12, 28,18, 30,70\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to yolov5-container-folds/yolov5-e-7-img-640-fold-32/labels.jpg... \n",
            "Image sizes 256 train, 256 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1myolov5-container-folds/yolov5-e-7-img-640-fold-32\u001b[0m\n",
            "Starting training for 5 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/4      1.41G     0.1875   0.007135          0        860        256: 100% 7/7 [00:13<00:00,  1.89s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.20it/s]\n",
            "                   all         54       1023   0.000617    0.00978   0.000319   6.54e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/4      1.41G     0.1815   0.007966          0        850        256: 100% 7/7 [00:00<00:00, 12.01it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.09s/it]\n",
            "                   all         54       1023   0.000679     0.0108   0.000379   7.39e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/4      1.41G     0.1788   0.008705          0       1114        256: 100% 7/7 [00:00<00:00, 12.19it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.29it/s]\n",
            "                   all         54       1023   0.000864     0.0137   0.000461   9.17e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/4      1.41G     0.1752   0.009131          0        725        256: 100% 7/7 [00:00<00:00, 11.77it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.10it/s]\n",
            "                   all         54       1023   0.000802     0.0127   0.000417   9.26e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/4      1.41G     0.1717    0.01003          0        736        256: 100% 7/7 [00:00<00:00, 13.18it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.45it/s]\n",
            "                   all         54       1023   0.000802     0.0127   0.000421   9.31e-05\n",
            "\n",
            "5 epochs completed in 0.006 hours.\n",
            "Optimizer stripped from yolov5-container-folds/yolov5-e-7-img-640-fold-32/weights/last.pt, 14.3MB\n",
            "Optimizer stripped from yolov5-container-folds/yolov5-e-7-img-640-fold-32/weights/best.pt, 14.3MB\n",
            "\n",
            "Validating yolov5-container-folds/yolov5-e-7-img-640-fold-32/weights/best.pt...\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.42it/s]\n",
            "                   all         54       1023   0.000864     0.0137   0.000461   9.17e-05\n",
            "Results saved to \u001b[1myolov5-container-folds/yolov5-e-7-img-640-fold-32\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▄█▆▆█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▃████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▃█▆▆█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▃█▆▆█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▄▃▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss ▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▁▃▅▆█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss █▆▄▂▁▄\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▃▅▇█▅\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▆▅▃▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▆█▇▂\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▁▆█▇▂\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.00046\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 9e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.00086\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.01369\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.00046\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 9e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.00086\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.01369\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.1717\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.01003\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.17505\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.00456\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.06671\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00071\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00071\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33myolov5-e-7-img-640-fold-3\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/oyh5800/yolov5-container-folds/runs/t82ggx5t\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 13 media file(s), 1 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230724_221405-t82ggx5t/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ⚠️ wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
            "###########################################################################################\n",
            "\n",
            "FOLD NUMBER:  4\n",
            "WARNING ⚠️ 'ultralytics.yolo.v8' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.models.yolo' instead.\n",
            "WARNING ⚠️ 'ultralytics.yolo.utils' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.utils' instead.\n",
            "Note this warning may be related to loading older models. You can update your model to current structure with:\n",
            "    import torch\n",
            "    ckpt = torch.load(\"model.pt\")  # applies to both official and custom models\n",
            "    torch.save(ckpt, \"updated-model.pt\")\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ⚠️ wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33moyh5800\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=, cfg=/content/yolov5/models/yolov5s.yaml, data=/content/yolov5/data/data_fold_4.yaml, hyp=yolov5/data/hyps/hyp.scratch-low.yaml, epochs=5, batch_size=32, imgsz=256, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5-container-folds, name=yolov5-e-7-img-640-fold-4, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v7.0-196-gacdf73b Python-3.10.6 torch-2.0.1+cu118 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov5-container-folds', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20230724_221606-705fv2fk\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33myolov5-e-7-img-640-fold-4\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/oyh5800/yolov5-container-folds\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/oyh5800/yolov5-container-folds/runs/705fv2fk\u001b[0m\n",
            "ClearML Task: created new task id=52c12c204c9e4200bdaf43aca9a52ff0\n",
            "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
            "ClearML results page: https://app.clear.ml/projects/cd2916daae6a43339843d1e80c424e51/experiments/52c12c204c9e4200bdaf43aca9a52ff0/output/log\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "YOLOv5s summary: 214 layers, 7022326 parameters, 7022326 gradients, 15.9 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset_folds_4/train/labels.cache... 218 images, 0 backgrounds, 0 corrupt: 100% 218/218 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB ram): 100% 218/218 [00:01<00:00, 214.96it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset_folds_4/valid/labels.cache... 54 images, 0 backgrounds, 0 corrupt: 100% 54/54 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram): 100% 54/54 [00:00<00:00, 81.00it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m1.09 anchors/target, 0.650 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mWARNING ⚠️ Extremely small objects found: 2819 of 7809 labels are <3 pixels in size\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 7680 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.7628: 100% 1000/1000 [00:01<00:00, 942.75it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 0.9983 best possible recall, 5.55 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=256, metric_all=0.355/0.758-mean/best, past_thr=0.496-mean: 3,3, 5,2, 3,6, 5,5, 8,8, 16,5, 13,13, 45,12, 17,72\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to yolov5-container-folds/yolov5-e-7-img-640-fold-42/labels.jpg... \n",
            "Image sizes 256 train, 256 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1myolov5-container-folds/yolov5-e-7-img-640-fold-42\u001b[0m\n",
            "Starting training for 5 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/4      1.41G     0.1877   0.005809          0        679        256: 100% 7/7 [00:12<00:00,  1.74s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.20it/s]\n",
            "                   all         54       2344    0.00117    0.00811   0.000606   0.000155\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/4      1.41G     0.1824   0.006534          0        820        256: 100% 7/7 [00:00<00:00, 12.29it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.37it/s]\n",
            "                   all         54       2344    0.00142    0.00981   0.000724   0.000167\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/4      1.41G       0.18   0.006867          0        577        256: 100% 7/7 [00:00<00:00, 13.16it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.41it/s]\n",
            "                   all         54       2344    0.00142    0.00981   0.000744   0.000165\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/4      1.41G     0.1759   0.007714          0        738        256: 100% 7/7 [00:00<00:00, 12.41it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.03it/s]\n",
            "                   all         54       2344    0.00148     0.0102   0.000821    0.00017\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/4      1.41G     0.1724   0.007876          0        668        256: 100% 7/7 [00:00<00:00, 12.22it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.20it/s]\n",
            "                   all         54       2344    0.00136    0.00939   0.000699   0.000137\n",
            "\n",
            "5 epochs completed in 0.006 hours.\n",
            "Optimizer stripped from yolov5-container-folds/yolov5-e-7-img-640-fold-42/weights/last.pt, 14.3MB\n",
            "Optimizer stripped from yolov5-container-folds/yolov5-e-7-img-640-fold-42/weights/best.pt, 14.3MB\n",
            "\n",
            "Validating yolov5-container-folds/yolov5-e-7-img-640-fold-42/weights/best.pt...\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.30it/s]\n",
            "                   all         54       2344    0.00148     0.0102   0.000844   0.000172\n",
            "Results saved to \u001b[1myolov5-container-folds/yolov5-e-7-img-640-fold-42\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▄▅▇▄█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▅▇▇█▁█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▇▇█▅█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▇▇█▅█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▆▄▃▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss ▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▁▃▅▇█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss █▆▄▂▁▂\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▃▄▆█▆\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▆▅▃▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▆█▇▂\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▁▆█▇▂\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.00082\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.00017\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.00148\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.01024\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.00084\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.00017\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.00148\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.01024\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.17244\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.00788\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.17244\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.00691\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.06671\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00071\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00071\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33myolov5-e-7-img-640-fold-4\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/oyh5800/yolov5-container-folds/runs/705fv2fk\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 12 media file(s), 1 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230724_221606-705fv2fk/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ⚠️ wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
            "###########################################################################################\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_WEIGHTS = [\n",
        "    'content/yolov5-container-folds/yolov5s-e-7-img-640-fold-0/weights/best.pt',\n",
        "    'content/yolov5-container-folds/yolov5s-e-7-img-640-fold-1/weights/best.pt',\n",
        "    'content/yolov5-container-folds/yolov5s-e-7-img-640-fold-2/weights/best.pt',\n",
        "    'content/yolov5-container-folds/yolov5s-e-7-img-640-fold-3/weights/best.pt',\n",
        "    'content/yolov5-container-folds/yolov5s-e-7-img-640-fold-4/weights/best.pt',\n",
        "]\n",
        "\n",
        "SOURCES = [\n",
        "    'content/dataset_folds_0/valid/images',\n",
        "    'content/dataset_folds_1/valid/images',\n",
        "    'content/dataset_folds_2/valid/images',\n",
        "    'content/dataset_folds_3/valid/images',\n",
        "    'content/dataset_folds_4/valid/images',\n",
        "]\n",
        "\n",
        "CONFIDENCE = [\n",
        "    0.179, 0.209, 0.268, 0.269, 0.308\n",
        "]"
      ],
      "metadata": {
        "id": "lloGPjYVq7t3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train YOLOv5s on kari on 10 epochs\n",
        "!python /content/yolov5/train.py --img 640  --batch 16 --epochs 7 --data /content/dir1/data.yaml --weights '' --cfg /content/yolov5/models/yolov5s.yaml --cache"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUxzQhhUd-RF",
        "outputId": "f0481c22-28dc-4600-fa3b-ed4347b5ea24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING ⚠️ 'ultralytics.yolo.v8' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.models.yolo' instead.\n",
            "WARNING ⚠️ 'ultralytics.yolo.utils' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.utils' instead.\n",
            "Note this warning may be related to loading older models. You can update your model to current structure with:\n",
            "    import torch\n",
            "    ckpt = torch.load(\"model.pt\")  # applies to both official and custom models\n",
            "    torch.save(ckpt, \"updated-model.pt\")\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ⚠️ wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33moyh5800\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=, cfg=/content/yolov5/models/yolov5s.yaml, data=/content/dir1/data.yaml, hyp=yolov5/data/hyps/hyp.scratch-low.yaml, epochs=7, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5/runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov5/train.py\", line 647, in <module>\n",
            "    main(opt)\n",
            "  File \"/content/yolov5/train.py\", line 511, in main\n",
            "    check_file(opt.data), check_yaml(opt.cfg), check_yaml(opt.hyp), str(opt.weights), str(opt.project)  # checks\n",
            "  File \"/content/yolov5/utils/general.py\", line 458, in check_file\n",
            "    assert len(files), f'File not found: {file}'  # assert file was found\n",
            "AssertionError: File not found: /content/dir1/data.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "/content/yolov5-container-folds/yolov5-e-7-img-640-fold-2/weights/best.pt"
      ],
      "metadata": {
        "id": "zOc97mIy4UyT",
        "outputId": "3d43ddd4-a74b-48c2-f988-90474d743a74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-63957302daed>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcontent\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0myolov5\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mfolds\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0myolov5\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m640\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'content' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.rmtree('/content/yolov5/runs/detect')"
      ],
      "metadata": {
        "id": "fME-Q3pU6Ny_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for fold in range(1):\n",
        "  print('FOLD NUMBER: ', fold)\n",
        "\n",
        "  !python yolov5/detect.py --weight /content/yolov5-container-folds/yolov5-e-7-img-640-fold-{fold}/weights/best.pt \\\n",
        "  --source /content/temporaryforcolab/test_images \\\n",
        "  --img 640 \\\n",
        "  --save-txt \\\n",
        "  --save-conf\\\n",
        "  --augment\n",
        "  print('###########################################################################################\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVXlYXexwHjP",
        "outputId": "a223b19a-3db8-4a07-84e3-387075341b36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD NUMBER:  0\n",
            "WARNING ⚠️ 'ultralytics.yolo.v8' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.models.yolo' instead.\n",
            "WARNING ⚠️ 'ultralytics.yolo.utils' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.utils' instead.\n",
            "Note this warning may be related to loading older models. You can update your model to current structure with:\n",
            "    import torch\n",
            "    ckpt = torch.load(\"model.pt\")  # applies to both official and custom models\n",
            "    torch.save(ckpt, \"updated-model.pt\")\n",
            "\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/yolov5-container-folds/yolov5-e-7-img-640-fold-0/weights/best.pt'], source=/content/temporaryforcolab/test_images, data=yolov5/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_conf=True, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=True, visualize=False, update=False, project=yolov5/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 🚀 v7.0-196-gacdf73b Python-3.10.6 torch-2.0.1+cu118 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "image 1/177 /content/temporaryforcolab/test_images/OBJ00607_PS3_K3_NIA0086.png: 640x640 (no detections), 200.1ms\n",
            "image 2/177 /content/temporaryforcolab/test_images/OBJ01347_PS3_K3_NIA0092.png: 640x640 (no detections), 18.7ms\n",
            "image 3/177 /content/temporaryforcolab/test_images/OBJ01357_PS3_K3_NIA0092.png: 640x640 (no detections), 18.3ms\n",
            "image 4/177 /content/temporaryforcolab/test_images/OBJ01527_PS3_K3_NIA0095.png: 640x640 (no detections), 18.9ms\n",
            "image 5/177 /content/temporaryforcolab/test_images/OBJ01675_PS3_K3_NIA0102.png: 640x640 (no detections), 19.5ms\n",
            "image 6/177 /content/temporaryforcolab/test_images/OBJ01701_PS3_K3_NIA0102.png: 640x640 (no detections), 18.5ms\n",
            "image 7/177 /content/temporaryforcolab/test_images/OBJ01925_PS3_K3_NIA0110.png: 640x640 (no detections), 18.8ms\n",
            "image 8/177 /content/temporaryforcolab/test_images/OBJ02240_PS3_K3_NIA0117.png: 640x640 (no detections), 18.1ms\n",
            "image 9/177 /content/temporaryforcolab/test_images/OBJ02477_PS3_K3_NIA0123.png: 640x640 (no detections), 18.7ms\n",
            "image 10/177 /content/temporaryforcolab/test_images/OBJ02546_PS3_K3_NIA0124.png: 640x640 (no detections), 19.3ms\n",
            "image 11/177 /content/temporaryforcolab/test_images/OBJ03321_PS3_K3A_NIA0137.png: 640x640 (no detections), 18.3ms\n",
            "image 12/177 /content/temporaryforcolab/test_images/OBJ03368_PS3_K3A_NIA0137.png: 640x640 (no detections), 18.4ms\n",
            "image 13/177 /content/temporaryforcolab/test_images/OBJ03369_PS3_K3A_NIA0137.png: 640x640 (no detections), 18.5ms\n",
            "image 14/177 /content/temporaryforcolab/test_images/OBJ03391_PS3_K3A_NIA0137.png: 640x640 (no detections), 18.4ms\n",
            "image 15/177 /content/temporaryforcolab/test_images/OBJ03424_PS3_K3A_NIA0139.png: 640x640 (no detections), 18.7ms\n",
            "image 16/177 /content/temporaryforcolab/test_images/OBJ03425_PS3_K3A_NIA0139.png: 640x640 (no detections), 18.5ms\n",
            "image 17/177 /content/temporaryforcolab/test_images/OBJ03426_PS3_K3A_NIA0139.png: 640x640 (no detections), 18.1ms\n",
            "image 18/177 /content/temporaryforcolab/test_images/OBJ03445_PS3_K3A_NIA0139.png: 640x640 (no detections), 18.7ms\n",
            "image 19/177 /content/temporaryforcolab/test_images/OBJ03477_PS3_K3A_NIA0142.png: 640x640 (no detections), 18.2ms\n",
            "image 20/177 /content/temporaryforcolab/test_images/OBJ03481_PS3_K3A_NIA0143.png: 640x640 (no detections), 18.3ms\n",
            "image 21/177 /content/temporaryforcolab/test_images/OBJ03540_PS3_K3A_NIA0148.png: 640x640 (no detections), 18.4ms\n",
            "image 22/177 /content/temporaryforcolab/test_images/OBJ03563_PS3_K3A_NIA0150.png: 640x640 (no detections), 18.3ms\n",
            "image 23/177 /content/temporaryforcolab/test_images/OBJ03570_PS3_K3A_NIA0150.png: 640x640 (no detections), 18.1ms\n",
            "image 24/177 /content/temporaryforcolab/test_images/OBJ03572_PS3_K3A_NIA0150.png: 640x640 (no detections), 18.6ms\n",
            "image 25/177 /content/temporaryforcolab/test_images/OBJ03579_PS3_K3A_NIA0151.png: 640x640 (no detections), 18.6ms\n",
            "image 26/177 /content/temporaryforcolab/test_images/OBJ03594_PS3_K3A_NIA0151.png: 640x640 (no detections), 18.8ms\n",
            "image 27/177 /content/temporaryforcolab/test_images/OBJ03597_PS3_K3A_NIA0151.png: 640x640 (no detections), 18.6ms\n",
            "image 28/177 /content/temporaryforcolab/test_images/OBJ03612_PS3_K3A_NIA0151.png: 640x640 (no detections), 18.3ms\n",
            "image 29/177 /content/temporaryforcolab/test_images/OBJ03614_PS3_K3A_NIA0151.png: 640x640 (no detections), 18.7ms\n",
            "image 30/177 /content/temporaryforcolab/test_images/OBJ03644_PS3_K3A_NIA0152.png: 640x640 (no detections), 18.8ms\n",
            "image 31/177 /content/temporaryforcolab/test_images/OBJ03649_PS3_K3A_NIA0153.png: 640x640 (no detections), 18.6ms\n",
            "image 32/177 /content/temporaryforcolab/test_images/OBJ03653_PS3_K3A_NIA0153.png: 640x640 (no detections), 18.7ms\n",
            "image 33/177 /content/temporaryforcolab/test_images/OBJ03687_PS3_K3A_NIA0154.png: 640x640 (no detections), 18.5ms\n",
            "image 34/177 /content/temporaryforcolab/test_images/OBJ03722_PS3_K3A_NIA0156.png: 640x640 (no detections), 18.6ms\n",
            "image 35/177 /content/temporaryforcolab/test_images/OBJ03786_PS3_K3A_NIA0158.png: 640x640 (no detections), 18.9ms\n",
            "image 36/177 /content/temporaryforcolab/test_images/OBJ03787_PS3_K3A_NIA0158.png: 640x640 (no detections), 18.6ms\n",
            "image 37/177 /content/temporaryforcolab/test_images/OBJ03809_PS3_K3A_NIA0159.png: 640x640 (no detections), 18.8ms\n",
            "image 38/177 /content/temporaryforcolab/test_images/OBJ03892_PS3_K3A_NIA0164.png: 640x640 (no detections), 18.4ms\n",
            "image 39/177 /content/temporaryforcolab/test_images/OBJ03896_PS3_K3A_NIA0164.png: 640x640 (no detections), 19.0ms\n",
            "image 40/177 /content/temporaryforcolab/test_images/OBJ03911_PS3_K3A_NIA0165.png: 640x640 (no detections), 18.8ms\n",
            "image 41/177 /content/temporaryforcolab/test_images/OBJ03942_PS3_K3A_NIA0166.png: 640x640 (no detections), 18.6ms\n",
            "image 42/177 /content/temporaryforcolab/test_images/OBJ03948_PS3_K3A_NIA0166.png: 640x640 (no detections), 18.6ms\n",
            "image 43/177 /content/temporaryforcolab/test_images/OBJ03951_PS3_K3A_NIA0166.png: 640x640 (no detections), 18.6ms\n",
            "image 44/177 /content/temporaryforcolab/test_images/OBJ03952_PS3_K3A_NIA0166.png: 640x640 (no detections), 18.8ms\n",
            "image 45/177 /content/temporaryforcolab/test_images/OBJ03962_PS3_K3A_NIA0166.png: 640x640 (no detections), 18.5ms\n",
            "image 46/177 /content/temporaryforcolab/test_images/OBJ03965_PS3_K3A_NIA0166.png: 640x640 (no detections), 18.4ms\n",
            "image 47/177 /content/temporaryforcolab/test_images/OBJ03972_PS3_K3A_NIA0166.png: 640x640 (no detections), 18.4ms\n",
            "image 48/177 /content/temporaryforcolab/test_images/OBJ03976_PS3_K3A_NIA0166.png: 640x640 (no detections), 18.3ms\n",
            "image 49/177 /content/temporaryforcolab/test_images/OBJ03983_PS3_K3A_NIA0166.png: 640x640 (no detections), 18.4ms\n",
            "image 50/177 /content/temporaryforcolab/test_images/OBJ03984_PS3_K3A_NIA0166.png: 640x640 (no detections), 18.4ms\n",
            "image 51/177 /content/temporaryforcolab/test_images/OBJ03985_PS3_K3A_NIA0166.png: 640x640 (no detections), 18.7ms\n",
            "image 52/177 /content/temporaryforcolab/test_images/OBJ04000_PS3_K3A_NIA0167.png: 640x640 (no detections), 18.9ms\n",
            "image 53/177 /content/temporaryforcolab/test_images/OBJ04011_PS3_K3A_NIA0167.png: 640x640 (no detections), 18.8ms\n",
            "image 54/177 /content/temporaryforcolab/test_images/OBJ04024_PS3_K3A_NIA0169.png: 640x640 (no detections), 19.2ms\n",
            "image 55/177 /content/temporaryforcolab/test_images/OBJ04031_PS3_K3A_NIA0169.png: 640x640 (no detections), 18.6ms\n",
            "image 56/177 /content/temporaryforcolab/test_images/OBJ04032_PS3_K3A_NIA0169.png: 640x640 (no detections), 18.5ms\n",
            "image 57/177 /content/temporaryforcolab/test_images/OBJ04100_PS3_K3A_NIA0174.png: 640x640 (no detections), 18.4ms\n",
            "image 58/177 /content/temporaryforcolab/test_images/OBJ04116_PS3_K3A_NIA0175.png: 640x640 (no detections), 18.3ms\n",
            "image 59/177 /content/temporaryforcolab/test_images/OBJ04118_PS3_K3A_NIA0175.png: 640x640 (no detections), 18.5ms\n",
            "image 60/177 /content/temporaryforcolab/test_images/OBJ04126_PS3_K3A_NIA0176.png: 640x640 (no detections), 18.0ms\n",
            "image 61/177 /content/temporaryforcolab/test_images/OBJ04129_PS3_K3A_NIA0176.png: 640x640 (no detections), 18.0ms\n",
            "image 62/177 /content/temporaryforcolab/test_images/OBJ04130_PS3_K3A_NIA0176.png: 640x640 (no detections), 18.1ms\n",
            "image 63/177 /content/temporaryforcolab/test_images/OBJ04136_PS3_K3A_NIA0177.png: 640x640 (no detections), 18.4ms\n",
            "image 64/177 /content/temporaryforcolab/test_images/OBJ04141_PS3_K3A_NIA0178.png: 640x640 (no detections), 18.4ms\n",
            "image 65/177 /content/temporaryforcolab/test_images/OBJ04148_PS3_K3A_NIA0179.png: 640x640 (no detections), 19.1ms\n",
            "image 66/177 /content/temporaryforcolab/test_images/OBJ04168_PS3_K3A_NIA0180.png: 640x640 (no detections), 18.2ms\n",
            "image 67/177 /content/temporaryforcolab/test_images/OBJ04178_PS3_K3A_NIA0180.png: 640x640 (no detections), 18.7ms\n",
            "image 68/177 /content/temporaryforcolab/test_images/OBJ04189_PS3_K3A_NIA0181.png: 640x640 (no detections), 18.5ms\n",
            "image 69/177 /content/temporaryforcolab/test_images/OBJ04337_PS3_K3A_NIA0282.png: 640x640 (no detections), 19.2ms\n",
            "image 70/177 /content/temporaryforcolab/test_images/OBJ04338_PS3_K3A_NIA0282.png: 640x640 (no detections), 20.1ms\n",
            "image 71/177 /content/temporaryforcolab/test_images/OBJ04348_PS3_K3A_NIA0283.png: 640x640 (no detections), 18.5ms\n",
            "image 72/177 /content/temporaryforcolab/test_images/OBJ04366_PS3_K3A_NIA0285.png: 640x640 (no detections), 18.8ms\n",
            "image 73/177 /content/temporaryforcolab/test_images/OBJ04403_PS3_K3A_NIA0289.png: 640x640 (no detections), 18.7ms\n",
            "image 74/177 /content/temporaryforcolab/test_images/OBJ04410_PS3_K3A_NIA0289.png: 640x640 (no detections), 18.4ms\n",
            "image 75/177 /content/temporaryforcolab/test_images/OBJ04413_PS3_K3A_NIA0289.png: 640x640 (no detections), 18.8ms\n",
            "image 76/177 /content/temporaryforcolab/test_images/OBJ04421_PS3_K3A_NIA0290.png: 640x640 (no detections), 19.0ms\n",
            "image 77/177 /content/temporaryforcolab/test_images/OBJ04444_PS3_K3A_NIA0292.png: 640x640 (no detections), 18.4ms\n",
            "image 78/177 /content/temporaryforcolab/test_images/OBJ04448_PS3_K3A_NIA0292.png: 640x640 (no detections), 18.5ms\n",
            "image 79/177 /content/temporaryforcolab/test_images/OBJ04461_PS3_K3A_NIA0293.png: 640x640 (no detections), 18.8ms\n",
            "image 80/177 /content/temporaryforcolab/test_images/OBJ04464_PS3_K3A_NIA0293.png: 640x640 (no detections), 18.9ms\n",
            "image 81/177 /content/temporaryforcolab/test_images/OBJ04479_PS3_K3A_NIA0294.png: 640x640 (no detections), 18.7ms\n",
            "image 82/177 /content/temporaryforcolab/test_images/OBJ04480_PS3_K3A_NIA0294.png: 640x640 (no detections), 18.7ms\n",
            "image 83/177 /content/temporaryforcolab/test_images/OBJ04521_PS3_K3A_NIA0299.png: 640x640 (no detections), 18.5ms\n",
            "image 84/177 /content/temporaryforcolab/test_images/OBJ04539_PS3_K3A_NIA0300.png: 640x640 (no detections), 18.9ms\n",
            "image 85/177 /content/temporaryforcolab/test_images/OBJ04556_PS3_K3A_NIA0300.png: 640x640 (no detections), 18.6ms\n",
            "image 86/177 /content/temporaryforcolab/test_images/OBJ04572_PS3_K3A_NIA0301.png: 640x640 (no detections), 18.8ms\n",
            "image 87/177 /content/temporaryforcolab/test_images/OBJ04599_PS3_K3A_NIA0302.png: 640x640 (no detections), 18.7ms\n",
            "image 88/177 /content/temporaryforcolab/test_images/OBJ04601_PS3_K3A_NIA0303.png: 640x640 (no detections), 18.5ms\n",
            "image 89/177 /content/temporaryforcolab/test_images/OBJ04629_PS3_K3A_NIA0304.png: 640x640 (no detections), 18.8ms\n",
            "image 90/177 /content/temporaryforcolab/test_images/OBJ04641_PS3_K3A_NIA0305.png: 640x640 (no detections), 18.7ms\n",
            "image 91/177 /content/temporaryforcolab/test_images/OBJ04643_PS3_K3A_NIA0306.png: 640x640 (no detections), 18.5ms\n",
            "image 92/177 /content/temporaryforcolab/test_images/OBJ04650_PS3_K3A_NIA0308.png: 640x640 (no detections), 18.5ms\n",
            "image 93/177 /content/temporaryforcolab/test_images/OBJ04652_PS3_K3A_NIA0308.png: 640x640 (no detections), 18.4ms\n",
            "image 94/177 /content/temporaryforcolab/test_images/OBJ04667_PS3_K3A_NIA0311.png: 640x640 (no detections), 18.2ms\n",
            "image 95/177 /content/temporaryforcolab/test_images/OBJ04692_PS3_K3A_NIA0312.png: 640x640 (no detections), 18.9ms\n",
            "image 96/177 /content/temporaryforcolab/test_images/OBJ04737_PS3_K3A_NIA0314.png: 640x640 (no detections), 18.4ms\n",
            "image 97/177 /content/temporaryforcolab/test_images/OBJ04754_PS3_K3A_NIA0314.png: 640x640 (no detections), 18.3ms\n",
            "image 98/177 /content/temporaryforcolab/test_images/OBJ04778_PS3_K3A_NIA0297.png: 640x640 (no detections), 19.1ms\n",
            "image 99/177 /content/temporaryforcolab/test_images/OBJ04786_PS3_K3A_NIA0297.png: 640x640 (no detections), 18.5ms\n",
            "image 100/177 /content/temporaryforcolab/test_images/OBJ04805_PS3_K3A_NIA0315.png: 640x640 (no detections), 18.5ms\n",
            "image 101/177 /content/temporaryforcolab/test_images/OBJ04807_PS3_K3A_NIA0315.png: 640x640 (no detections), 18.5ms\n",
            "image 102/177 /content/temporaryforcolab/test_images/OBJ04812_PS3_K3A_NIA0315.png: 640x640 (no detections), 18.3ms\n",
            "image 103/177 /content/temporaryforcolab/test_images/OBJ04814_PS3_K3A_NIA0315.png: 640x640 (no detections), 18.3ms\n",
            "image 104/177 /content/temporaryforcolab/test_images/OBJ04815_PS3_K3A_NIA0315.png: 640x640 (no detections), 18.4ms\n",
            "image 105/177 /content/temporaryforcolab/test_images/OBJ04816_PS3_K3A_NIA0315.png: 640x640 (no detections), 18.9ms\n",
            "image 106/177 /content/temporaryforcolab/test_images/OBJ04818_PS3_K3A_NIA0316.png: 640x640 (no detections), 18.6ms\n",
            "image 107/177 /content/temporaryforcolab/test_images/OBJ04824_PS3_K3A_NIA0316.png: 640x640 (no detections), 18.5ms\n",
            "image 108/177 /content/temporaryforcolab/test_images/OBJ04864_PS3_K3A_NIA0318.png: 640x640 (no detections), 18.4ms\n",
            "image 109/177 /content/temporaryforcolab/test_images/OBJ04871_PS3_K3A_NIA0318.png: 640x640 (no detections), 18.3ms\n",
            "image 110/177 /content/temporaryforcolab/test_images/OBJ04879_PS3_K3A_NIA0318.png: 640x640 (no detections), 19.2ms\n",
            "image 111/177 /content/temporaryforcolab/test_images/OBJ04884_PS3_K3A_NIA0319.png: 640x640 (no detections), 18.3ms\n",
            "image 112/177 /content/temporaryforcolab/test_images/OBJ04909_PS3_K3A_NIA0322.png: 640x640 (no detections), 18.1ms\n",
            "image 113/177 /content/temporaryforcolab/test_images/OBJ04931_PS3_K3A_NIA0172.png: 640x640 (no detections), 18.4ms\n",
            "image 114/177 /content/temporaryforcolab/test_images/OBJ04939_PS3_K3A_NIA0324.png: 640x640 (no detections), 18.8ms\n",
            "image 115/177 /content/temporaryforcolab/test_images/OBJ04940_PS3_K3A_NIA0324.png: 640x640 (no detections), 19.0ms\n",
            "image 116/177 /content/temporaryforcolab/test_images/OBJ04959_PS3_K3A_NIA0326.png: 640x640 (no detections), 18.6ms\n",
            "image 117/177 /content/temporaryforcolab/test_images/OBJ04999_PS3_K3A_NIA0328.png: 640x640 (no detections), 18.4ms\n",
            "image 118/177 /content/temporaryforcolab/test_images/OBJ05004_PS3_K3A_NIA0328.png: 640x640 (no detections), 18.8ms\n",
            "image 119/177 /content/temporaryforcolab/test_images/OBJ05040_PS3_K3A_NIA0329.png: 640x640 (no detections), 18.2ms\n",
            "image 120/177 /content/temporaryforcolab/test_images/OBJ05053_PS3_K3A_NIA0329.png: 640x640 (no detections), 18.4ms\n",
            "image 121/177 /content/temporaryforcolab/test_images/OBJ05068_PS3_K3A_NIA0330.png: 640x640 (no detections), 19.6ms\n",
            "image 122/177 /content/temporaryforcolab/test_images/OBJ05073_PS3_K3A_NIA0331.png: 640x640 (no detections), 18.3ms\n",
            "image 123/177 /content/temporaryforcolab/test_images/OBJ05086_PS3_K3A_NIA0332.png: 640x640 (no detections), 18.9ms\n",
            "image 124/177 /content/temporaryforcolab/test_images/OBJ05103_PS3_K3A_NIA0333.png: 640x640 (no detections), 18.6ms\n",
            "image 125/177 /content/temporaryforcolab/test_images/OBJ05117_PS3_K3A_NIA0333.png: 640x640 (no detections), 18.6ms\n",
            "image 126/177 /content/temporaryforcolab/test_images/OBJ05133_PS3_K3A_NIA0334.png: 640x640 (no detections), 18.2ms\n",
            "image 127/177 /content/temporaryforcolab/test_images/OBJ05134_PS3_K3A_NIA0334.png: 640x640 (no detections), 18.3ms\n",
            "image 128/177 /content/temporaryforcolab/test_images/OBJ05149_PS3_K3A_NIA0335.png: 640x640 (no detections), 18.4ms\n",
            "image 129/177 /content/temporaryforcolab/test_images/OBJ05153_PS3_K3A_NIA0336.png: 640x640 (no detections), 18.3ms\n",
            "image 130/177 /content/temporaryforcolab/test_images/OBJ05188_PS3_K3A_NIA0340.png: 640x640 (no detections), 18.3ms\n",
            "image 131/177 /content/temporaryforcolab/test_images/OBJ05207_PS3_K3A_NIA0340.png: 640x640 (no detections), 18.5ms\n",
            "image 132/177 /content/temporaryforcolab/test_images/OBJ05213_PS3_K3A_NIA0340.png: 640x640 (no detections), 18.4ms\n",
            "image 133/177 /content/temporaryforcolab/test_images/OBJ05214_PS3_K3A_NIA0340.png: 640x640 (no detections), 19.0ms\n",
            "image 134/177 /content/temporaryforcolab/test_images/OBJ05222_PS3_K3A_NIA0341.png: 640x640 (no detections), 18.2ms\n",
            "image 135/177 /content/temporaryforcolab/test_images/OBJ05254_PS3_K3A_NIA0341.png: 640x640 (no detections), 18.5ms\n",
            "image 136/177 /content/temporaryforcolab/test_images/OBJ05286_PS3_K3A_NIA0342.png: 640x640 (no detections), 18.6ms\n",
            "image 137/177 /content/temporaryforcolab/test_images/OBJ05288_PS3_K3A_NIA0342.png: 640x640 (no detections), 18.6ms\n",
            "image 138/177 /content/temporaryforcolab/test_images/OBJ05300_PS3_K3A_NIA0344.png: 640x640 (no detections), 18.4ms\n",
            "image 139/177 /content/temporaryforcolab/test_images/OBJ05307_PS3_K3A_NIA0344.png: 640x640 (no detections), 18.6ms\n",
            "image 140/177 /content/temporaryforcolab/test_images/OBJ05313_PS3_K3A_NIA0344.png: 640x640 (no detections), 18.2ms\n",
            "image 141/177 /content/temporaryforcolab/test_images/OBJ05326_PS3_K3A_NIA0345.png: 640x640 (no detections), 19.0ms\n",
            "image 142/177 /content/temporaryforcolab/test_images/OBJ05347_PS3_K3A_NIA0345.png: 640x640 (no detections), 18.3ms\n",
            "image 143/177 /content/temporaryforcolab/test_images/OBJ05364_PS3_K3A_NIA0346.png: 640x640 (no detections), 18.4ms\n",
            "image 144/177 /content/temporaryforcolab/test_images/OBJ05375_PS3_K3A_NIA0346.png: 640x640 (no detections), 18.3ms\n",
            "image 145/177 /content/temporaryforcolab/test_images/OBJ05382_PS3_K3A_NIA0346.png: 640x640 (no detections), 18.4ms\n",
            "image 146/177 /content/temporaryforcolab/test_images/OBJ05397_PS3_K3A_NIA0347.png: 640x640 (no detections), 18.3ms\n",
            "image 147/177 /content/temporaryforcolab/test_images/OBJ05417_PS3_K3A_NIA0349.png: 640x640 (no detections), 18.5ms\n",
            "image 148/177 /content/temporaryforcolab/test_images/OBJ05423_PS3_K3A_NIA0349.png: 640x640 (no detections), 18.6ms\n",
            "image 149/177 /content/temporaryforcolab/test_images/OBJ05424_PS3_K3A_NIA0349.png: 640x640 (no detections), 18.6ms\n",
            "image 150/177 /content/temporaryforcolab/test_images/OBJ05428_PS3_K3A_NIA0350.png: 640x640 (no detections), 18.7ms\n",
            "image 151/177 /content/temporaryforcolab/test_images/OBJ05429_PS3_K3A_NIA0350.png: 640x640 (no detections), 18.5ms\n",
            "image 152/177 /content/temporaryforcolab/test_images/OBJ05464_PS3_K3A_NIA0166.png: 640x640 (no detections), 18.5ms\n",
            "image 153/177 /content/temporaryforcolab/test_images/OBJ05465_PS3_K3A_NIA0166.png: 640x640 (no detections), 18.4ms\n",
            "image 154/177 /content/temporaryforcolab/test_images/OBJ05474_PS3_K3A_NIA0166.png: 640x640 (no detections), 18.3ms\n",
            "image 155/177 /content/temporaryforcolab/test_images/OBJ05475_PS3_K3A_NIA0166.png: 640x640 (no detections), 18.6ms\n",
            "image 156/177 /content/temporaryforcolab/test_images/OBJ05502_PS3_K3A_NIA0166.png: 640x640 (no detections), 19.1ms\n",
            "image 157/177 /content/temporaryforcolab/test_images/OBJ05504_PS3_K3A_NIA0166.png: 640x640 (no detections), 18.5ms\n",
            "image 158/177 /content/temporaryforcolab/test_images/OBJ05508_PS3_K3A_NIA0166.png: 640x640 (no detections), 18.6ms\n",
            "image 159/177 /content/temporaryforcolab/test_images/OBJ05518_PS3_K3A_NIA0352.png: 640x640 (no detections), 18.4ms\n",
            "image 160/177 /content/temporaryforcolab/test_images/OBJ05524_PS3_K3A_NIA0352.png: 640x640 (no detections), 18.4ms\n",
            "image 161/177 /content/temporaryforcolab/test_images/OBJ05544_PS3_K3A_NIA0354.png: 640x640 (no detections), 18.5ms\n",
            "image 162/177 /content/temporaryforcolab/test_images/OBJ05549_PS3_K3A_NIA0354.png: 640x640 (no detections), 18.6ms\n",
            "image 163/177 /content/temporaryforcolab/test_images/OBJ05575_PS3_K3A_NIA0355.png: 640x640 (no detections), 18.4ms\n",
            "image 164/177 /content/temporaryforcolab/test_images/OBJ05594_PS3_K3A_NIA0357.png: 640x640 (no detections), 18.5ms\n",
            "image 165/177 /content/temporaryforcolab/test_images/OBJ05611_PS3_K3A_NIA0357.png: 640x640 (no detections), 18.7ms\n",
            "image 166/177 /content/temporaryforcolab/test_images/OBJ05629_PS3_K3A_NIA0358.png: 640x640 (no detections), 18.7ms\n",
            "image 167/177 /content/temporaryforcolab/test_images/OBJ05645_PS3_K3A_NIA0359.png: 640x640 (no detections), 18.5ms\n",
            "image 168/177 /content/temporaryforcolab/test_images/OBJ05646_PS3_K3A_NIA0359.png: 640x640 (no detections), 18.5ms\n",
            "image 169/177 /content/temporaryforcolab/test_images/OBJ05651_PS3_K3A_NIA0359.png: 640x640 (no detections), 19.2ms\n",
            "image 170/177 /content/temporaryforcolab/test_images/OBJ05724_PS3_K3A_NIA0363.png: 640x640 (no detections), 18.6ms\n",
            "image 171/177 /content/temporaryforcolab/test_images/OBJ05727_PS3_K3A_NIA0363.png: 640x640 (no detections), 18.8ms\n",
            "image 172/177 /content/temporaryforcolab/test_images/OBJ05747_PS3_K3A_NIA0364.png: 640x640 (no detections), 27.5ms\n",
            "image 173/177 /content/temporaryforcolab/test_images/OBJ05827_PS3_K3A_NIA0595.png: 640x640 (no detections), 18.6ms\n",
            "image 174/177 /content/temporaryforcolab/test_images/OBJ05836_PS3_K3A_NIA0598.png: 640x640 (no detections), 19.4ms\n",
            "image 175/177 /content/temporaryforcolab/test_images/OBJ05840_PS3_K3_NIA0600.png: 640x640 (no detections), 18.6ms\n",
            "image 176/177 /content/temporaryforcolab/test_images/OBJ06535_PS3_K3_NIA0689.png: 640x640 (no detections), 18.5ms\n",
            "image 177/177 /content/temporaryforcolab/test_images/OBJ07401_PS3_K3A_NIA0817.png: 640x640 (no detections), 18.5ms\n",
            "Speed: 0.6ms pre-process, 19.7ms inference, 0.3ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1myolov5/runs/detect/exp\u001b[0m\n",
            "0 labels saved to yolov5/runs/detect/exp/labels\n",
            "###########################################################################################\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ensemble-boxes"
      ],
      "metadata": {
        "id": "kGlkwPTo0FZ5",
        "outputId": "9f9a3e7c-3179-4f99-ff52-1d91d2f63824",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ensemble-boxes\n",
            "  Downloading ensemble_boxes-1.0.9-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ensemble-boxes) (1.22.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from ensemble-boxes) (1.5.3)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from ensemble-boxes) (0.56.4)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->ensemble-boxes) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba->ensemble-boxes) (67.7.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ensemble-boxes) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ensemble-boxes) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->ensemble-boxes) (1.16.0)\n",
            "Installing collected packages: ensemble-boxes\n",
            "Successfully installed ensemble-boxes-1.0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import pandas as pd\n",
        "import os\n",
        "def yolo_to_x1y1x2y2x3y3x4y4(yolo_coords):\n",
        "    \"\"\"\n",
        "    YOLO 형식의 bounding box 좌표를 x1, y1, x2, y2, x3, y3, x4, y4 형식으로 변환하는 함수\n",
        "    \"\"\"\n",
        "    x, y, w, h = yolo_coords\n",
        "    x1, y1 = x - w/2, y - h/2\n",
        "    x2, y2 = x + w/2, y - h/2\n",
        "    x3, y3 = x - w/2, y + h/2\n",
        "    x4, y4 = x + w/2, y + h/2\n",
        "    return x1, y1, x2, y2, x3, y3, x4, y4"
      ],
      "metadata": {
        "id": "4keR65Fl0lfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python content/detect.py --source ../../data/data_splited/data_yolo/images/test --save-txt --save-conf --weight ../../ckpts/yolov5x-endoscopy/endoscopy/weights/best.pt --imgsz 576 --device 0 --augment\n"
      ],
      "metadata": {
        "id": "Ud3jeBBO2FAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Load a model\n",
        "    model = YOLO('/content/yolov5-container-folds/yolov5-e-7-img-640-fold-0/weights/best.pt')\n",
        "    results = model.predict(source='/content/temporaryforcolab/test_images', save=True, save_txt=True)\n",
        "\n",
        "    data = []\n",
        "    for result in results:\n",
        "        boxes = result.boxes.cpu().numpy()\n",
        "        for box in boxes:\n",
        "            file_name = os.path.splitext(os.path.basename(result.path))[0][:8]\n",
        "            conf = box.conf[0]\n",
        "            x1, y1, x2, y2, x3, y3, x4, y4 = yolo_to_x1y1x2y2x3y3x4y4(box.xywh[0])\n",
        "            data.append([file_name, conf, x1, y1, x2, y2, x3, y3, x4, y4])\n",
        "\n",
        "    df = pd.DataFrame(data, columns=['File', 'Confidence', 'X1', 'Y1', 'X2', 'Y2', 'X3', 'Y3', 'X4', 'Y4'])\n",
        "    df.to_csv('content/results/submission1.csv', index=False)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "7hhpevrKCP8Q",
        "outputId": "5a131e15-9af7-47a8-842e-eba38c231f27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mtorch_safe_load\u001b[0;34m(weight)\u001b[0m\n\u001b[1;32m    560\u001b[0m                 'ultralytics.yolo.data': 'ultralytics.data'}):  # for legacy 8.0 Classify and Pose models\n\u001b[0;32m--> 561\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m  \u001b[0;31m# load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    808\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUNSAFE_MESSAGE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    810\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1172\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mfind_class\u001b[0;34m(self, mod_name, name)\u001b[0m\n\u001b[1;32m   1164\u001b[0m             \u001b[0mmod_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_module_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1165\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'models'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-3b06b480a724>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-67-3b06b480a724>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Load a model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/yolov5-container-folds/yolov5-e-7-img-640-fold-0/weights/best.pt'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pretrained YOLOv8n model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/temporaryforcolab/test_images'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_txt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, task)\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(self, weights, task)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0msuffix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msuffix\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'.pt'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mckpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattempt_load_one_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'task'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverrides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset_ckpt_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mattempt_load_one_weight\u001b[0;34m(weight, device, inplace, fuse)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mattempt_load_one_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m     \u001b[0;34m\"\"\"Loads a single model weights.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m     \u001b[0mckpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch_safe_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# load ckpt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mDEFAULT_CFG_DICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_args'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m  \u001b[0;31m# combine model and default args, preferring model args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ema'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mckpt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# FP32 model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mtorch_safe_load\u001b[0;34m(weight)\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# e.name is missing module name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'models'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m             raise TypeError(\n\u001b[0m\u001b[1;32m    566\u001b[0m                 emojis(f'ERROR ❌️ {weight} appears to be an Ultralytics YOLOv5 model originally trained '\n\u001b[1;32m    567\u001b[0m                        \u001b[0;34mf'with https://github.com/ultralytics/yolov5.\\nThis model is NOT forwards compatible with '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: ERROR ❌️ /content/yolov5-container-folds/yolov5-e-7-img-640-fold-0/weights/best.pt appears to be an Ultralytics YOLOv5 model originally trained with https://github.com/ultralytics/yolov5.\nThis model is NOT forwards compatible with YOLOv8 at https://github.com/ultralytics/ultralytics.\nRecommend fixes are to train a new model using the latest 'ultralytics' package or to run a command with an official YOLOv8 model, i.e. 'yolo predict model=yolov8n.pt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for fold in range(NUM_FOLD):\n",
        "  print('FOLD NUMBER: ', fold)\n",
        "\n",
        "  !python yolov5/detect.py --weights {MODEL_WEIGHTS[fold]} \\"
      ],
      "metadata": {
        "id": "6qRs9k_v0ehl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}