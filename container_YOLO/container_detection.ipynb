{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Colabì—ì„œ ëŒì•„ê°€ê¸° ìœ„í•´ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤\n",
        "\n",
        "1. google mountëŠ” ë„ˆë¬´ ëŠë ¤ì„œ ê°œì¸ repoì— íŒŒì¼ì„ ì˜¬ë¦¬ê³  cloneí–ˆìŠµë‹ˆë‹¤.\n",
        "2. imageì—ëŠ” png íŒŒì¼ë§Œ ì¡´ì¬í•©ë‹ˆë‹¤\n",
        "3. kfold, ensemble, wb ëŠ” https://www.kaggle.com/code/ayuraj/train-yolov5-cross-validation-ensemble-w-b ì™€ https://medium.com/@edusubin/k-fold-file-splitting-for-segmentation-networks-like-u-net-613ed013ec15 ë¥¼ ì°¸ê³ í–ˆìŠµë‹ˆë‹¤\n"
      ],
      "metadata": {
        "id": "qkanmzm6KeZf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://movie5: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@github.com/movie5/temporaryforcolab.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v13D-r3oAaKb",
        "outputId": "b2ee70e0-5735-4208-ff75-3aa26f95105b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'temporaryforcolab'...\n",
            "remote: Enumerating objects: 729, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 729 (delta 0), reused 3 (delta 0), pack-reused 726\u001b[K\n",
            "Receiving objects: 100% (729/729), 728.12 MiB | 17.57 MiB/s, done.\n",
            "Resolving deltas: 100% (54/54), done.\n",
            "Updating files: 100% (722/722), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# YOLOv5ë¥¼ githubì—ì„œ ë‹¤ìš´ë°›ì•„ ì‚¬ìš©í•©ë‹ˆë‹¤"
      ],
      "metadata": {
        "id": "-nXxxLXcKv7a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download YOLOv5\n",
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "# Install dependencies\n",
        "%pip install -qr yolov5/requirements.txt  # install dependencies"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaOJHvXyed1M",
        "outputId": "e5ebd728-31e7-45ac-e6e4-56468fa6b9c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'yolov5' already exists and is not an empty directory.\n",
            "/\n",
            "Setup complete. Using torch 2.0.1+cu118 (NVIDIA A100-SXM4-40GB)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd content/yolov5"
      ],
      "metadata": {
        "id": "8iFebqJD_H3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "QBsW_QRw_OIz",
        "outputId": "1aa54270-e95e-4b9f-e279-4d9fb194651f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bin\t\t\t    etc     media\t\t      root  tools\n",
            "boot\t\t\t    home    mnt\t\t\t      run   usr\n",
            "content\t\t\t    lib     NGC-DL-CONTAINER-LICENSE  sbin  var\n",
            "cuda-keyring_1.0-1_all.deb  lib32   opt\t\t\t      srv\n",
            "datalab\t\t\t    lib64   proc\t\t      sys\n",
            "dev\t\t\t    libx32  python-apt\t\t      tmp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install -qr /content/yolov5/requirements.txt # install dependencies"
      ],
      "metadata": {
        "id": "Ums7RFUK_BWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## í•™ìŠµìƒí™©ì„ íŒŒì•…í•˜ê³  ëª¨ë¸ íŒŒë¼ë¯¸í„°ë¥¼ ë³´ê¸° ìœ„í•´ wandbë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.\n",
        "\n",
        "í•„ìˆ˜ëŠ” ì•„ë‹ˆë‹ˆ ë„˜ê²¨ë„ ì¢‹ìŠµë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "UFFbrpoTK4aR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install W&B\n",
        "!pip install -q --upgrade wandb\n",
        "# Login\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "BttJTcUmemG-",
        "outputId": "eb8e796a-3cbe-49e3-96d4-00b096e4a307"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m214.7/214.7 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Necessary/extra dependencies.\n",
        "import os\n",
        "import gc\n",
        "import cv2\n",
        "import glob\n",
        "import json\n",
        "import wandb\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "pd.set_option('mode.chained_assignment', None)\n",
        "from tqdm import tqdm\n",
        "from shutil import copyfile\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "#customize iPython writefile so we can write variables\n",
        "from IPython.core.magic import register_line_cell_magic\n",
        "\n",
        "@register_line_cell_magic\n",
        "def writetemplate(line, cell):\n",
        "    with open(line, 'w') as f:\n",
        "        f.write(cell.format(**globals()))"
      ],
      "metadata": {
        "id": "z9FM-NPRfAAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ë³€í™˜í•´ì£¼ëŠ” ì½”ë“œì…ë‹ˆë‹¤. ì§€ìš°ë‹˜ì˜ ì½”ë“œì…ë‹ˆë‹¤"
      ],
      "metadata": {
        "id": "I0SiVSNuLWwU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_coordinates(coords_str, image_width=1024, image_height=1024):\n",
        "  coords = coords_str.split(',')\n",
        "  x1, y1, x2, y2, x3, y3, x4, y4 = map(float, coords)\n",
        "  x = (x1 + x2 + x3 + x4) / 4\n",
        "  y = (y1 + y2 + y3 + y4) / 4\n",
        "  width = max(x1, x2, x3, x4) - min(x1, x2, x3, x4)\n",
        "  height = max(y1, y2, y3, y4) - min(y1, y2, y3, y4)\n",
        "\n",
        "  # ì •ê·œí™”ëœ ì¢Œí‘œ ê³„ì‚°(0-1ì‚¬ì´)\n",
        "  x_normalized = x / image_width\n",
        "  y_normalized = y / image_height\n",
        "  width_normalized = width / image_width\n",
        "  height_normalized = height / image_height\n",
        "  return x_normalized, y_normalized, width_normalized, height_normalized"
      ],
      "metadata": {
        "id": "wFAyEEYpAqjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd temporaryforcolab"
      ],
      "metadata": {
        "id": "ZFOr1zfER3Ie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvnkbsE4XSeJ",
        "outputId": "064ec3b8-0ffd-4702-c1ea-eba3cf0943e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data  temporaryforcolab\tyolov5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ìœ„ ê²°ê³¼ë¡œ ë³´ì´ë“¯ì´ cdë¥¼ í•´ë„ ì´ë™ì´ ì•ˆë˜ì„œ ì´í›„ ê²½ë¡œë“¤ì€ ì ˆëŒ€ê²½ë¡œì…ë‹ˆë‹¤.\n",
        "\n",
        "ì•„ë˜ëŠ” create_yolo_annodations í•¨ìˆ˜ë¥¼ csvë¥¼ ê±°ì¹˜ì§€ ì•Šê³  í•œë²ˆì— ë³€í™˜í•´ì„œ txtë¡œ ë§Œë“¤ì–´ì£¼ëŠ” ì½”ë“œì…ë‹ˆë‹¤.\n",
        "\n",
        "ì €ëŠ” ìˆ˜ë™ KFOLDë¥¼ êµ¬í˜„í•˜ê¸° ìœ„í•´ ì•„ì§ train, validation splitì„ í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n",
        "\n",
        "yoloí˜•ì‹ì˜ txt annotation íŒŒì¼ì€ ì§ì ‘ ìƒì„±í•œ train_labels_txt í´ë”ì— ì €ì¥í•˜ê²Œ ë©ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "VOqB5GZaLk_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# kfoldí•˜ê¸° ìœ„í•´ 272ê°œ íŒŒì¼ì˜ í™•ì¥ì ì „ê¹Œì§€ ëª…ì¹­ì„ ë¦¬ìŠ¤íŠ¸ì— ì €ì¥í•˜ì—¬ ì¸ë±ìŠ¤ë¡œ ì°¾ì•„ì„œ ì‚¬ìš©í•©ë‹ˆë‹¤\n",
        "id_list = []\n",
        "\n",
        "# txt íŒŒì¼ì„ ì €ì¥í•  í´ë”ì˜ ê²½ë¡œë¥¼ ì¸ìˆ˜ë¡œ ë°›ìŠµë‹ˆë‹¤.\n",
        "def create_yolo_annotations(label_folder):\n",
        "  train_jsons = sorted(glob.glob('/content/temporaryforcolab/train_labels/*'))\n",
        "  for j in train_jsons:\n",
        "    #json íŒŒì¼ í•˜ë‚˜ë¥¼ ì—½ë‹ˆë‹¤\n",
        "    with open(j, 'r') as f:\n",
        "      # coord ë¦¬ìŠ¤íŠ¸ì˜ í•œ ì¸ë±ìŠ¤ì— object ê°œìˆ˜ë§Œí¼ ì¢Œí‘œê°€ ë“¤ì–´ê°‘ë‹ˆë‹¤\n",
        "      coord = []\n",
        "      tmp = json.load(f)\n",
        "      #ë¨¼ì € txtíŒŒì¼ì˜ ì´ë¦„ê³¼ ê²½ë¡œë¥¼ ë§Œë“¤ì–´ ì¤ë‹ˆë‹¤.\n",
        "      txt_name = tmp['features'][0]['properties']['image_id'][:-3] + \"txt\"\n",
        "      txt_path = os.path.join(label_folder, txt_name)\n",
        "      #feature ì•ˆì˜ propertiesì—ì„œ object imcoordsë¥¼ stringìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤\n",
        "      for o in tmp['features']:\n",
        "        object_imcoords = o['properties']['object_imcoords']\n",
        "        coord.append(object_imcoords)\n",
        "    #í•˜ë‚˜ì˜ jsoníŒŒì¼ì—ì„œ object_imcoordsë¥¼ ëª¨ë‘ ë¶ˆëŸ¬ì˜¤ë©´ txtíŒŒì¼ì„ ì‘ì„±í•©ë‹ˆë‹¤\n",
        "    with open(txt_path, 'w') as t:\n",
        "      for r in coord:\n",
        "        # yolo data formatì— ë§ì¶”ì–´ ì‘ì„±í•©ë‹ˆë‹¤.\n",
        "        x, y, width, height = convert_coordinates(r)\n",
        "        #í•˜ë‚˜ì˜ í´ë˜ìŠ¤ë§Œ ìˆê¸° ë•Œë¬¸ì— 0ì„ í´ë˜ìŠ¤ë¡œ ë‘ê³  x,y, width, heightë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤\n",
        "        t.write(f'0 {x:.6f} {y:.6f} {width:.6f} {height:.6f}\\n')\n",
        "\n",
        "    # í•˜ë‚˜ì˜ yolo txtê°€ ì‘ì„±ë˜ë©´ ê·¸ íŒŒì¼ì˜ ì´ë¦„ì„ id listì— ì¶”ê°€í•©ë‹ˆë‹¤.\n",
        "    id_list.append(tmp['features'][0]['properties']['image_id'][:-3])"
      ],
      "metadata": {
        "id": "Pny7yTqBBTRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## os.makedirsë¡œ í´ë”ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "_kOGEyedNrEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/content/temporaryforcolab/train_label_txt')"
      ],
      "metadata": {
        "id": "iW02hCNhNdMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_yolo_annotations('/content/temporaryforcolab/train_label_txt')"
      ],
      "metadata": {
        "id": "A__ugziCSXyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ì•„ë˜ì˜ ì½”ë“œë¡œ 272ê°œ ëª¨ë‘ ì‘ì„±ë˜ì—ˆìŒì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "IDsHuxKnOBPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "initial_count = 0\n",
        "for path in pathlib.Path('temporaryforcolab/train_label_txt').iterdir():\n",
        "    if path.is_file():\n",
        "        initial_count += 1\n",
        "\n",
        "print(initial_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sexkBFry3HrI",
        "outputId": "b2ede51b-d828-4bc9-e1f8-8264abfdf001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "272\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ì´ ì•„ë˜ì—ëŠ” í•™ìŠµì„ ìœ„í•´ ì„¤ì¹˜í•œ ë„êµ¬ ì…ë‹ˆë‹¤. ê¼­ í•„ìš”í•œ ê²ƒì€ ì•„ë‹ˆë¯€ë¡œ ë„˜ì–´ê°€ì…”ë„ ì¢‹ìŠµë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "ax8_oCQIOG1G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ClearML"
      ],
      "metadata": {
        "id": "9OBdl2gZb0UG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Select YOLOv5 ğŸš€ logger {run: 'auto'}\n",
        "logger = 'ClearML' #@param ['Comet', 'ClearML', 'TensorBoard']\n",
        "\n",
        "if logger == 'Comet':\n",
        "  %pip install -q comet_ml\n",
        "  import comet_ml; comet_ml.init()\n",
        "elif logger == 'ClearML':\n",
        "  %pip install -q clearml\n",
        "  import clearml; clearml.browser_login()\n",
        "elif logger == 'TensorBoard':\n",
        "  %load_ext tensorboard\n",
        "  %tensorboard --logdir runs/train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "lwq4FKpAbz0T",
        "outputId": "c90a515d-08a4-44cb-dd63-fd9fa6b8e034"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "                    window._ApiKey = new Promise((resolve, reject) => {\n",
              "                        const timeout = setTimeout(() => reject(\"Failed authenticating existing browser session\"), 5000)\n",
              "                        fetch(\"https://app.clear.ml/api/auth.login\", {\n",
              "                          method: 'GET',\n",
              "                          credentials: 'include'\n",
              "                        })\n",
              "                          .then((response) => resolve(response.json()))\n",
              "                          .then((json) => {\n",
              "                            clearTimeout(timeout);\n",
              "                          }).catch((err) => {\n",
              "                            clearTimeout(timeout);\n",
              "                            reject(err);\n",
              "                        });\n",
              "                    });\n",
              "                    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ¤– ClearML connected successfully - let's build something! ğŸš€\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ì•„ë˜ëŠ” 5 KFOLD cross validationì„ êµ¬í˜„í•˜ê³ ì ìˆ˜ë™ìœ¼ë¡œ êµ¬í˜„í•œ 5ê°œì˜ kfold train-validation ë¶„ë¦¬ì…ë‹ˆë‹¤"
      ],
      "metadata": {
        "id": "N-hxqKwfOYU8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "KFOLD for train/valid set!!\n",
        "\n",
        "---\n",
        "Source file structure\n",
        "\n",
        "->temporaryforcolab\n",
        "\n",
        "---->train_images\n",
        "\n",
        "---->train_label_txt\n",
        "\n",
        "---\n",
        "\n",
        "Destination file structure\n",
        "\n",
        "->content\n",
        "\n",
        "-->dataset_folds_0\n",
        "\n",
        "------------->train\n",
        "\n",
        "--------------------------->images\n",
        "\n",
        "--------------------------->labels\n",
        "\n",
        "------------->valid\n",
        "\n",
        "--------------------------->images\n",
        "\n",
        "--------------------------->labels\n",
        "\n",
        "-->dataset_folds_1\n",
        "\n",
        "------------->train\n",
        "\n",
        "--------------------------->images\n",
        "\n",
        "--------------------------->labels\n",
        "\n",
        "------------->valid\n",
        "\n",
        "--------------------------->images\n",
        "\n",
        "--------------------------->labels\n",
        "\n",
        "--> yolov5"
      ],
      "metadata": {
        "id": "w2BYb6xvtjR1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dir_names = ['dataset_folds_0','dataset_folds_1','dataset_folds_2','dataset_folds_3','dataset_folds_4']\n",
        "#validation_image_number = 54\n",
        "data_root = os.path.join(os.getcwd(),'temporaryforcolab')"
      ],
      "metadata": {
        "id": "ZjRa9_L3t0Qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_root"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "W8jC863S42kc",
        "outputId": "15633aa3-cd3e-4663-b164-4a5f0b1ac2f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/temporaryforcolab'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 272ë¥¼ 5-kfold í•´ë³´ì.\n",
        "\n",
        "54ê°œë¥¼ validationìœ¼ë¡œ ë‘”ë‹¤. ê·¸ëŸ¬ë©´ ë‚¨ì€ 218ê°œëŠ” trainìœ¼ë¡œ ë‘ê²Œ ëœë‹¤"
      ],
      "metadata": {
        "id": "St4Ehg0xwrBJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ì´ ì½”ë“œëŠ” id_list[0+i:54+i]ê°€ ì˜ ëŒì•„ê°€ëŠ” ì½”ë“œì¸ì§€ í™•ì¸í•˜ê¸° ìœ„í•œ ê²ƒ\n",
        "\"\"\"\n",
        "i = 0\n",
        "for _ in range(5):\n",
        "  test_files = id_list[0+i:54+i]\n",
        "  print(test_files[0], len(test_files), i)\n",
        "  i += 54"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Unb4ufXm39pa",
        "outputId": "86012c8d-8a18-43cf-d6d9-3cc297bc68c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OBJ00013_PS3_K3_NIA0078. 54 0\n",
            "OBJ03828_PS3_K3A_NIA0161. 54 54\n",
            "OBJ04437_PS3_K3A_NIA0291. 54 108\n",
            "OBJ04915_PS3_K3A_NIA0322. 54 162\n",
            "OBJ05395_PS3_K3A_NIA0347. 54 216\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "#ë³µì‚¬ë  ì›ë³¸ ì´ë¯¸ì§€ì™€ ë¼ë²¨ì˜ ê²½ë¡œ\n",
        "img_data_root = os.path.join(data_root,'train_images')\n",
        "label_data_root = os.path.join(data_root,'train_label_txt')\n",
        "\n",
        "for dir_name in dir_names:\n",
        "  print(dir_name)\n",
        "  #í´ë” ìƒì„±\n",
        "  os.makedirs(dir_name)\n",
        "\n",
        "  #making sub directoreis train and test\n",
        "  os.makedirs(os.path.join(os.getcwd(),dir_name,'train'))\n",
        "  os.makedirs(os.path.join(os.getcwd(),dir_name,'valid'))\n",
        "\n",
        "  #locating to the image and label directory\n",
        "  train_dir = os.path.join(os.getcwd(),dir_name,'train')\n",
        "  valid_dir = os.path.join(os.getcwd(),dir_name,'valid')\n",
        "\n",
        "  #making train and val sub-directories\n",
        "  os.makedirs(os.path.join(train_dir,'images'))\n",
        "  os.makedirs(os.path.join(train_dir,'labels'))\n",
        "  os.makedirs(os.path.join(valid_dir,'images'))\n",
        "  os.makedirs(os.path.join(valid_dir,'labels'))\n",
        "\n",
        "  #creating file names for validation\n",
        "\n",
        "  test_filenames =id_list[0+i:54+i]\n",
        "  for filename in test_filenames:\n",
        "    # validation 54ê°œ ë§Œí¼ ì¸ë±ìŠ¤ (0, 53), (54, 97) ê°€ dir0, dir1ì— ê°€ê²Œ ëœë‹¤\n",
        "    img_dest = os.path.join(os.getcwd(),dir_name,'valid', 'images')\n",
        "    label_dest = os.path.join(os.getcwd(),dir_name,'valid', 'labels')\n",
        "\n",
        "    #ì˜®ê²¨ì§€ê²Œ ë  fileì˜ í™•ì¥ìë¥¼ í¬í•¨í•œ ê²½ë¡œ\n",
        "    img_file_path = os.path.join(img_data_root,filename+'png')\n",
        "    label_file_path = os.path.join(label_data_root,filename+'txt')\n",
        "\n",
        "    # val image, labelì´ ì˜®ê²¨ì§€ê²Œ ëœë‹¤.\n",
        "    shutil.copy(img_file_path,img_dest)\n",
        "    shutil.copy(label_file_path,label_dest)\n",
        "\n",
        "  #saving files for training(valì— ë“¤ì–´ê°€ì§€ ì•Šì€ íŒŒì¼ë“¤)\n",
        "  for other_filename in id_list:\n",
        "    if other_filename in test_filenames:\n",
        "      continue\n",
        "    else:\n",
        "      # train 272-54 = 216ê°œ ë§Œí¼ ì¸ë±ìŠ¤ (54, 271), (0~53, 98~271) ê°€ dir0, dir1ì— ê°€ê²Œ ëœë‹¤\n",
        "      img_dest = os.path.join(os.getcwd(),dir_name,'train', 'images')\n",
        "      label_dest = os.path.join(os.getcwd(),dir_name,'train', 'labels')\n",
        "\n",
        "      img_file_path = os.path.join(img_data_root,other_filename + 'png')\n",
        "      label_file_path = os.path.join(label_data_root,other_filename+'txt')\n",
        "\n",
        "      shutil.copy(img_file_path,img_dest)\n",
        "      shutil.copy(label_file_path,label_dest)\n",
        "  #í•œ datafolderì— ê°€ê²Œ ë˜ë©´ ë‹¤ìŒ 54ê°œì— ëŒ€í•´ì„œ ìˆ˜í–‰í•œë‹¤\n",
        "  i+=54"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3lbwLfyuKvl",
        "outputId": "cbd27953-98ad-4b91-e014-17fccb25a9f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset_folds_0\n",
            "dataset_folds_1\n",
            "dataset_folds_2\n",
            "dataset_folds_3\n",
            "dataset_folds_4\n",
            "dataset_folds_5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ì˜ ì…ë ¥ì´ ë˜ì—ˆë‚˜ í™•ì¸í•´ë³´ëŠ” ì½”ë“œ 54ê°œë¡œ ì˜ ë¶„ë°°ë˜ì—ˆìŒì„ ì•Œ ìˆ˜ ìˆë‹¤."
      ],
      "metadata": {
        "id": "LBdcIDwmWmo1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "initial_count = 0\n",
        "for path in pathlib.Path('/content/dataset_folds_1/images/val').iterdir():\n",
        "    if path.is_file():\n",
        "        initial_count += 1\n",
        "        print(path)\n",
        "\n",
        "print(initial_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3dcjKOM1Hmp",
        "outputId": "a638fa74-d12a-4b88-97f2-77ef956a1c88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/dataset_folds_1/images/val/OBJ04042_PS3_K3A_NIA0170.png\n",
            "/content/dataset_folds_1/images/val/OBJ04135_PS3_K3A_NIA0177.png\n",
            "/content/dataset_folds_1/images/val/OBJ04153_PS3_K3A_NIA0179.png\n",
            "/content/dataset_folds_1/images/val/OBJ03945_PS3_K3A_NIA0166.png\n",
            "/content/dataset_folds_1/images/val/OBJ04026_PS3_K3A_NIA0169.png\n",
            "/content/dataset_folds_1/images/val/OBJ04351_PS3_K3A_NIA0283.png\n",
            "/content/dataset_folds_1/images/val/OBJ04407_PS3_K3A_NIA0289.png\n",
            "/content/dataset_folds_1/images/val/OBJ04370_PS3_K3A_NIA0285.png\n",
            "/content/dataset_folds_1/images/val/OBJ04361_PS3_K3A_NIA0285.png\n",
            "/content/dataset_folds_1/images/val/OBJ04088_PS3_K3A_NIA0173.png\n",
            "/content/dataset_folds_1/images/val/OBJ04028_PS3_K3A_NIA0169.png\n",
            "/content/dataset_folds_1/images/val/OBJ04382_PS3_K3A_NIA0287.png\n",
            "/content/dataset_folds_1/images/val/OBJ04376_PS3_K3A_NIA0286.png\n",
            "/content/dataset_folds_1/images/val/OBJ04093_PS3_K3A_NIA0174.png\n",
            "/content/dataset_folds_1/images/val/OBJ04038_PS3_K3A_NIA0170.png\n",
            "/content/dataset_folds_1/images/val/OBJ04123_PS3_K3A_NIA0175.png\n",
            "/content/dataset_folds_1/images/val/OBJ03967_PS3_K3A_NIA0166.png\n",
            "/content/dataset_folds_1/images/val/OBJ04360_PS3_K3A_NIA0285.png\n",
            "/content/dataset_folds_1/images/val/OBJ04053_PS3_K3A_NIA0170.png\n",
            "/content/dataset_folds_1/images/val/OBJ04125_PS3_K3A_NIA0176.png\n",
            "/content/dataset_folds_1/images/val/OBJ04144_PS3_K3A_NIA0178.png\n",
            "/content/dataset_folds_1/images/val/OBJ03828_PS3_K3A_NIA0161.png\n",
            "/content/dataset_folds_1/images/val/OBJ03963_PS3_K3A_NIA0166.png\n",
            "/content/dataset_folds_1/images/val/OBJ04422_PS3_K3A_NIA0290.png\n",
            "/content/dataset_folds_1/images/val/OBJ04386_PS3_K3A_NIA0287.png\n",
            "/content/dataset_folds_1/images/val/OBJ03947_PS3_K3A_NIA0166.png\n",
            "/content/dataset_folds_1/images/val/OBJ04064_PS3_K3A_NIA0171.png\n",
            "/content/dataset_folds_1/images/val/OBJ03836_PS3_K3A_NIA0161.png\n",
            "/content/dataset_folds_1/images/val/OBJ03840_PS3_K3A_NIA0161.png\n",
            "/content/dataset_folds_1/images/val/OBJ04152_PS3_K3A_NIA0179.png\n",
            "/content/dataset_folds_1/images/val/OBJ04393_PS3_K3A_NIA0288.png\n",
            "/content/dataset_folds_1/images/val/OBJ04059_PS3_K3A_NIA0171.png\n",
            "/content/dataset_folds_1/images/val/OBJ04431_PS3_K3A_NIA0290.png\n",
            "/content/dataset_folds_1/images/val/OBJ04022_PS3_K3A_NIA0169.png\n",
            "/content/dataset_folds_1/images/val/OBJ03885_PS3_K3A_NIA0164.png\n",
            "/content/dataset_folds_1/images/val/OBJ04356_PS3_K3A_NIA0284.png\n",
            "/content/dataset_folds_1/images/val/OBJ03864_PS3_K3A_NIA0162.png\n",
            "/content/dataset_folds_1/images/val/OBJ03964_PS3_K3A_NIA0166.png\n",
            "/content/dataset_folds_1/images/val/OBJ03950_PS3_K3A_NIA0166.png\n",
            "/content/dataset_folds_1/images/val/OBJ04238_PS3_K3_NIA0278.png\n",
            "/content/dataset_folds_1/images/val/OBJ04323_PS3_K3_NIA0280.png\n",
            "/content/dataset_folds_1/images/val/OBJ03970_PS3_K3A_NIA0166.png\n",
            "/content/dataset_folds_1/images/val/OBJ04397_PS3_K3A_NIA0289.png\n",
            "/content/dataset_folds_1/images/val/OBJ04070_PS3_K3A_NIA0171.png\n",
            "/content/dataset_folds_1/images/val/OBJ04052_PS3_K3A_NIA0170.png\n",
            "/content/dataset_folds_1/images/val/OBJ03932_PS3_K3A_NIA0166.png\n",
            "/content/dataset_folds_1/images/val/OBJ04396_PS3_K3A_NIA0289.png\n",
            "/content/dataset_folds_1/images/val/OBJ04186_PS3_K3A_NIA0180.png\n",
            "/content/dataset_folds_1/images/val/OBJ04019_PS3_K3A_NIA0169.png\n",
            "/content/dataset_folds_1/images/val/OBJ04419_PS3_K3A_NIA0289.png\n",
            "/content/dataset_folds_1/images/val/OBJ04066_PS3_K3A_NIA0171.png\n",
            "/content/dataset_folds_1/images/val/OBJ03941_PS3_K3A_NIA0166.png\n",
            "/content/dataset_folds_1/images/val/OBJ04018_PS3_K3A_NIA0169.png\n",
            "/content/dataset_folds_1/images/val/OBJ04143_PS3_K3A_NIA0178.png\n",
            "54\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸœ Create .YAML file\n",
        "###The data.yaml, is the dataset configuration file that defines\n",
        "\n",
        "1. an \"optional\" download command/URL for auto-downloading,\n",
        "2. a path to a directory of training images (or path to a *.txt file with a list of training images),\n",
        "3. a path to a directory of validation images (or path to a *.txt file with a list of validation images),\n",
        "the number of classes,\n",
        "4. a list of class names.\n",
        "\n",
        "<tip>\n",
        " ğŸ“ Important: In this competition, each image can either belong to opacity or none image-level labels. That's why I have used the number of classes, nc to be 2. YOLOv5 automatically handles the images without any bounding box coordinates.\n",
        "\n",
        "ğŸ“ Note: The data.yaml is created in the yolov5/data directory as required.\n",
        "</tip>"
      ],
      "metadata": {
        "id": "q7FXQoFZWueU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create .yaml file\n",
        "import yaml\n",
        "NUM_FOLD = 5\n",
        "for fold in range(NUM_FOLD):\n",
        "    data_yaml = dict(\n",
        "        train = f'../dataset_folds_{fold}/train',\n",
        "        val = f'../dataset_folds_{fold}/valid',\n",
        "        nc = 1,\n",
        "        names = ['container']\n",
        "    )\n",
        "\n",
        "    # Note that I am creating the file in the yolov5/data/ directory.\n",
        "    with open(f'yolov5/data/data_fold_{fold}.yaml', 'w') as outfile:\n",
        "        yaml.dump(data_yaml, outfile, default_flow_style=True)\n",
        "\n",
        "%cat yolov5/data/data_fold_0.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E65qpL6CXNKk",
        "outputId": "8a68e190-b65d-4f44-bd88-30762c94c4ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{names: [container], nc: 1, train: ../dataset_folds_0/images/train, val: ../dataset_folds_0/images/valid}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "cdê°€ ì•ˆë˜ì„œ ì ˆëŒ€ê²½ë¡œë¥¼ ì”ë‹ˆë‹¤....ã… ã… ã… \n",
        "\n",
        "--img {IMG_SIZE} \\ # Input image size = 640\n",
        "\n",
        "--batch {BATCH_SIZE} \\ # Batch size = 16\n",
        "\n",
        "--epochs {EPOCHS} \\ # Number of epochs = 7\n",
        "\n",
        "--data data.yaml \\ # Configuration file\n",
        "\n",
        "--weights '' \\ # We don't use pretrained\n",
        "\n",
        "--seed = {SEED} # SeedëŠ” 77ë¡œ fix\n",
        "\n",
        "--save_period 10 \\ # Save model after interval\n",
        "\n",
        "--project kaggle-siim-covid # W&B project name"
      ],
      "metadata": {
        "id": "vM9SX-QRY3h5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U ultralytics"
      ],
      "metadata": {
        "id": "edRSU4XgBbhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "def main():\n",
        "    model = YOLO(\"ultralytics/ultralytics/cfg/models/v5/yolov5.yaml\")\n",
        "    model.info()\n",
        "    model.train(data=\"C://Users/laboratory/repository/oiltank/oiltank_dataset/data.yaml\", epochs=500)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "XUL_XRixCdc3",
        "outputId": "26878ef1-8e42-447c-80ad-a56392e84311",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-93-2eaaae1297c2>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-93-2eaaae1297c2>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ultralytics/ultralytics/cfg/models/v5/yolov5.yaml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C://Users/laboratory/repository/oiltank/oiltank_dataset/data.yaml\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, task)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_suffix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.pt'\u001b[0m  \u001b[0;31m# add suffix, i.e. yolov8n -> yolov8n.pt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msuffix\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'.yaml'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36m_new\u001b[0;34m(self, cfg, task, verbose)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0mverbose\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdisplay\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0minfo\u001b[0m \u001b[0mon\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \"\"\"\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mcfg_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myaml_model_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mguess_model_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36myaml_model_load\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m     \u001b[0munified_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'(\\d+)([nslmx])(.+)?$'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mr'\\1\\3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# i.e. yolov8x.yaml -> yolov8.yaml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m     \u001b[0myaml_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_yaml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munified_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhard\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcheck_yaml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myaml_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myaml_file\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# model dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'scale'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mguess_model_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/utils/checks.py\u001b[0m in \u001b[0;36mcheck_yaml\u001b[0;34m(file, suffix, hard)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheck_yaml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.yaml'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.yml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhard\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;34m\"\"\"Search/download YAML file (if necessary) and return path, checking suffix.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcheck_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhard\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/utils/checks.py\u001b[0m in \u001b[0;36mcheck_file\u001b[0;34m(file, suffix, download, hard)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mROOT\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'cfg'\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'**'\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# find file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhard\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"'{file}' does not exist\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhard\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Multiple files match '{file}', specify exact path: {files}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: 'ultralytics/ultralytics/cfg/models/v5/yolov5.yaml' does not exist"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Model\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=False)\n"
      ],
      "metadata": {
        "id": "QZSKHg9TBjCG",
        "outputId": "487389ef-18b6-4a42-f63b-2a96b44b5ab3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/hub.py:286: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
            "  warnings.warn(\n",
            "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "WARNING âš ï¸ 'ultralytics.yolo.v8' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.models.yolo' instead.\n",
            "WARNING âš ï¸ 'ultralytics.yolo.utils' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.utils' instead.\n",
            "Note this warning may be related to loading older models. You can update your model to current structure with:\n",
            "    import torch\n",
            "    ckpt = torch.load(\"model.pt\")  # applies to both official and custom models\n",
            "    torch.save(ckpt, \"updated-model.pt\")\n",
            "\n",
            "YOLOv5 ğŸš€ 2023-7-24 Python-3.10.6 torch-2.0.1+cu118 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n",
            "\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1    229245  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "YOLOv5s summary: 214 layers, 7235389 parameters, 7235389 gradients, 16.6 GFLOPs\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.train(data=\"/content/yolov5/data/data_fold_4.yaml\", epochs=500)"
      ],
      "metadata": {
        "id": "loLVvB-gC9X6",
        "outputId": "6e05f900-8a59-4a4c-f1ad-3eaebf6b8a11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-94-3f02994df23e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/yolov5/data/data_fold_4.yaml\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: Module.train() got an unexpected keyword argument 'data'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "def main():\n",
        "    model = YOLO(\"ultralytics/ultralytics/cfg/models/v5/yolov5.yaml\")\n",
        "    model.info()\n",
        "    model.train(data=\"/content/yolov5/data/data_fold_4.yaml\", epochs=100)"
      ],
      "metadata": {
        "id": "RtxEVOf-BO_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/yolov5/train.py  --img 620 --batch 32 --epochs 200 --data /content/yolov5/data/data_fold_2.yaml --weights '' --cfg /content/yolov5/models/yolov5s.yaml --project yolov5-con --name yolov5-e-200-img-620-fold-2 --cache"
      ],
      "metadata": {
        "id": "_0KwPVd1_pXP",
        "outputId": "eda54474-7f98-42d2-f0a9-d589b81f058f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING âš ï¸ 'ultralytics.yolo.v8' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.models.yolo' instead.\n",
            "WARNING âš ï¸ 'ultralytics.yolo.utils' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.utils' instead.\n",
            "Note this warning may be related to loading older models. You can update your model to current structure with:\n",
            "    import torch\n",
            "    ckpt = torch.load(\"model.pt\")  # applies to both official and custom models\n",
            "    torch.save(ckpt, \"updated-model.pt\")\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING âš ï¸ wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33moyh5800\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=, cfg=/content/yolov5/models/yolov5s.yaml, data=/content/yolov5/data/data_fold_2.yaml, hyp=content/yolov5/data/hyps/hyp.scratch-low.yaml, epochs=200, batch_size=32, imgsz=620, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5-con, name=yolov5-e-200-img-620-fold-2, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
            "YOLOv5 ğŸš€ v7.0-196-gacdf73b Python-3.10.6 torch-2.0.1+cu118 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 ğŸš€ runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov5-con', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/wandb/run-20230724_225604-tu7v4o1k\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33myolov5-e-200-img-620-fold-2\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/oyh5800/yolov5-con\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/oyh5800/yolov5-con/runs/tu7v4o1k\u001b[0m\n",
            "ClearML Task: created new task id=8d7c537c76164d3aa550c025dffc926a\n",
            "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
            "ClearML results page: https://app.clear.ml/projects/42ab783900fd4bc29b4cc94bf6770d84/experiments/8d7c537c76164d3aa550c025dffc926a/output/log\n",
            "\n",
            "Dataset not found âš ï¸, missing paths ['/content/dataset_folds_2/valid']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov5/train.py\", line 647, in <module>\n",
            "    main(opt)\n",
            "  File \"/content/yolov5/train.py\", line 536, in main\n",
            "    train(opt.hyp, opt, device, callbacks)\n",
            "  File \"/content/yolov5/train.py\", line 117, in train\n",
            "    data_dict = data_dict or check_dataset(data)  # check if None\n",
            "  File \"/content/yolov5/utils/general.py\", line 517, in check_dataset\n",
            "    raise Exception('Dataset not found âŒ')\n",
            "Exception: Dataset not found âŒ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/yolov5/train.py  --img 640 --batch 32 --epochs 100 --data /content/yolov5/data/data_fold_3.yaml --weights '' --cfg /content/yolov5/models/yolov5s.yaml --project yolov5-con --name yolov5-e-7-img-640-fold-3 --cache"
      ],
      "metadata": {
        "id": "V2C-a-dUEqkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "  print('FOLD NUMBER: ', fold)\n",
        "\n",
        "  print('###########################################################################################\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Yt354YJZ4Nx",
        "outputId": "5d2b1696-0c35-4ead-f7e7-ae46c3b4b9c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD NUMBER:  1\n",
            "WARNING âš ï¸ 'ultralytics.yolo.v8' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.models.yolo' instead.\n",
            "WARNING âš ï¸ 'ultralytics.yolo.utils' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.utils' instead.\n",
            "Note this warning may be related to loading older models. You can update your model to current structure with:\n",
            "    import torch\n",
            "    ckpt = torch.load(\"model.pt\")  # applies to both official and custom models\n",
            "    torch.save(ckpt, \"updated-model.pt\")\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING âš ï¸ wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33moyh5800\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=, cfg=/content/yolov5/models/yolov5s.yaml, data=/content/yolov5/data/data_fold_1.yaml, hyp=yolov5/data/hyps/hyp.scratch-low.yaml, epochs=5, batch_size=32, imgsz=256, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5-container-folds, name=yolov5-e-7-img-640-fold-1, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
            "YOLOv5 ğŸš€ v7.0-196-gacdf73b Python-3.10.6 torch-2.0.1+cu118 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 ğŸš€ runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov5-container-folds', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20230724_221022-bqavb85g\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33myolov5-e-7-img-640-fold-1\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/oyh5800/yolov5-container-folds\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/oyh5800/yolov5-container-folds/runs/bqavb85g\u001b[0m\n",
            "ClearML Task: created new task id=175c37b4e7d942cea113089c9e8a4880\n",
            "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
            "ClearML results page: https://app.clear.ml/projects/cd2916daae6a43339843d1e80c424e51/experiments/175c37b4e7d942cea113089c9e8a4880/output/log\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "YOLOv5s summary: 214 layers, 7022326 parameters, 7022326 gradients, 15.9 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset_folds_1/train/labels.cache... 218 images, 0 backgrounds, 0 corrupt: 100% 218/218 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB ram): 100% 218/218 [00:01<00:00, 216.31it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset_folds_1/valid/labels.cache... 54 images, 0 backgrounds, 0 corrupt: 100% 54/54 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram): 100% 54/54 [00:00<00:00, 86.19it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m1.22 anchors/target, 0.697 Best Possible Recall (BPR). Anchors are a poor fit to dataset âš ï¸, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mWARNING âš ï¸ Extremely small objects found: 2330 of 7586 labels are <3 pixels in size\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 7512 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.7698: 100% 1000/1000 [00:01<00:00, 949.38it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 0.9993 best possible recall, 5.75 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=256, metric_all=0.370/0.767-mean/best, past_thr=0.508-mean: 3,3, 6,3, 3,6, 6,5, 7,7, 10,10, 19,18, 34,15, 17,102\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone âœ… (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to yolov5-container-folds/yolov5-e-7-img-640-fold-12/labels.jpg... \n",
            "Image sizes 256 train, 256 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1myolov5-container-folds/yolov5-e-7-img-640-fold-12\u001b[0m\n",
            "Starting training for 5 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/4      1.41G     0.1823   0.006528          0        964        256: 100% 7/7 [00:10<00:00,  1.53s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.18it/s]\n",
            "                   all         54       2567   0.000556    0.00351   0.000281   6.86e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/4      1.41G     0.1782   0.007082          0        915        256: 100% 7/7 [00:00<00:00, 10.19it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.06s/it]\n",
            "                   all         54       2567   0.000679    0.00429   0.000343   7.82e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/4      1.41G     0.1748   0.007339          0       1133        256: 100% 7/7 [00:00<00:00, 13.61it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.42it/s]\n",
            "                   all         54       2567   0.000679    0.00429   0.000344   5.64e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/4      1.41G     0.1723   0.007229          0        541        256: 100% 7/7 [00:00<00:00, 12.90it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.24it/s]\n",
            "                   all         54       2567   0.000556    0.00351   0.000288   4.55e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/4      1.41G     0.1688   0.009027          0        674        256: 100% 7/7 [00:00<00:00, 12.89it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.32it/s]\n",
            "                   all         54       2567   0.000432    0.00273   0.000238   3.64e-05\n",
            "\n",
            "5 epochs completed in 0.005 hours.\n",
            "Optimizer stripped from yolov5-container-folds/yolov5-e-7-img-640-fold-12/weights/last.pt, 14.3MB\n",
            "Optimizer stripped from yolov5-container-folds/yolov5-e-7-img-640-fold-12/weights/best.pt, 14.3MB\n",
            "\n",
            "Validating yolov5-container-folds/yolov5-e-7-img-640-fold-12/weights/best.pt...\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.29it/s]\n",
            "                   all         54       2567   0.000679    0.00429   0.000343   7.82e-05\n",
            "Results saved to \u001b[1myolov5-container-folds/yolov5-e-7-img-640-fold-12\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 â–„â–ˆâ–ˆâ–„â–â–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 â–†â–ˆâ–„â–ƒâ–â–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision â–…â–ˆâ–ˆâ–…â–â–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall â–…â–ˆâ–ˆâ–…â–â–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss â–ˆâ–†â–„â–ƒâ–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss â–â–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss â–â–ƒâ–ƒâ–ƒâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss â–ˆâ–†â–„â–‚â–â–†\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss â–â–â–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss â–â–ƒâ–„â–†â–ˆâ–ƒ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 â–ˆâ–†â–…â–ƒâ–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 â–â–†â–ˆâ–‡â–‚\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 â–â–†â–ˆâ–‡â–‚\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.00034\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 8e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.00068\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.00429\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.00034\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 8e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.00068\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.00429\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.1688\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.00903\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.17751\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.00577\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.06671\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00071\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00071\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run \u001b[33myolov5-e-7-img-640-fold-1\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/oyh5800/yolov5-container-folds/runs/bqavb85g\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 13 media file(s), 1 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230724_221022-bqavb85g/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING âš ï¸ wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
            "###########################################################################################\n",
            "\n",
            "FOLD NUMBER:  2\n",
            "WARNING âš ï¸ 'ultralytics.yolo.v8' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.models.yolo' instead.\n",
            "WARNING âš ï¸ 'ultralytics.yolo.utils' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.utils' instead.\n",
            "Note this warning may be related to loading older models. You can update your model to current structure with:\n",
            "    import torch\n",
            "    ckpt = torch.load(\"model.pt\")  # applies to both official and custom models\n",
            "    torch.save(ckpt, \"updated-model.pt\")\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING âš ï¸ wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33moyh5800\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=, cfg=/content/yolov5/models/yolov5s.yaml, data=/content/yolov5/data/data_fold_2.yaml, hyp=yolov5/data/hyps/hyp.scratch-low.yaml, epochs=5, batch_size=32, imgsz=256, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5-container-folds, name=yolov5-e-7-img-640-fold-2, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
            "YOLOv5 ğŸš€ v7.0-196-gacdf73b Python-3.10.6 torch-2.0.1+cu118 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 ğŸš€ runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov5-container-folds', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20230724_221223-lxsvlflx\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33myolov5-e-7-img-640-fold-2\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/oyh5800/yolov5-container-folds\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/oyh5800/yolov5-container-folds/runs/lxsvlflx\u001b[0m\n",
            "ClearML Task: created new task id=aceaa9da15ab43f6944299c3ae7b7da8\n",
            "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
            "ClearML results page: https://app.clear.ml/projects/cd2916daae6a43339843d1e80c424e51/experiments/aceaa9da15ab43f6944299c3ae7b7da8/output/log\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "YOLOv5s summary: 214 layers, 7022326 parameters, 7022326 gradients, 15.9 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset_folds_2/train/labels.cache... 218 images, 0 backgrounds, 0 corrupt: 100% 218/218 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB ram): 100% 218/218 [00:01<00:00, 207.14it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset_folds_2/valid/labels.cache... 54 images, 0 backgrounds, 0 corrupt: 100% 54/54 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram): 100% 54/54 [00:00<00:00, 81.39it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m1.18 anchors/target, 0.666 Best Possible Recall (BPR). Anchors are a poor fit to dataset âš ï¸, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mWARNING âš ï¸ Extremely small objects found: 2716 of 7998 labels are <3 pixels in size\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 7890 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.7545: 100% 1000/1000 [00:00<00:00, 1101.38it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 0.9982 best possible recall, 5.20 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=256, metric_all=0.342/0.750-mean/best, past_thr=0.505-mean: 3,3, 5,2, 3,6, 6,5, 8,8, 11,11, 21,31, 44,16, 15,102\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone âœ… (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to yolov5-container-folds/yolov5-e-7-img-640-fold-22/labels.jpg... \n",
            "Image sizes 256 train, 256 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1myolov5-container-folds/yolov5-e-7-img-640-fold-22\u001b[0m\n",
            "Starting training for 5 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/4      1.41G     0.1773   0.006785          0        798        256: 100% 7/7 [00:12<00:00,  1.85s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.21it/s]\n",
            "                   all         54       2155   0.000247    0.00186    0.00013   3.22e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/4      1.41G     0.1729   0.007469          0        832        256: 100% 7/7 [00:00<00:00, 11.15it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.38it/s]\n",
            "                   all         54       2155   0.000185    0.00139    9.9e-05   1.61e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/4      1.41G     0.1717   0.007654          0       1031        256: 100% 7/7 [00:00<00:00, 11.15it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.31it/s]\n",
            "                   all         54       2155   0.000185    0.00139   9.27e-05   1.55e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/4      1.41G     0.1698   0.007484          0        407        256: 100% 7/7 [00:00<00:00, 11.99it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.12it/s]\n",
            "                   all         54       2155   0.000123   0.000928   6.19e-05   1.86e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/4      1.41G     0.1661   0.009146          0        757        256: 100% 7/7 [00:00<00:00, 11.80it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.44it/s]\n",
            "                   all         54       2155   0.000123   0.000928   6.18e-05   2.16e-05\n",
            "\n",
            "5 epochs completed in 0.006 hours.\n",
            "Optimizer stripped from yolov5-container-folds/yolov5-e-7-img-640-fold-22/weights/last.pt, 14.3MB\n",
            "Optimizer stripped from yolov5-container-folds/yolov5-e-7-img-640-fold-22/weights/best.pt, 14.3MB\n",
            "\n",
            "Validating yolov5-container-folds/yolov5-e-7-img-640-fold-22/weights/best.pt...\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.31it/s]\n",
            "                   all         54       2155   0.000247    0.00186    0.00013   3.22e-05\n",
            "Results saved to \u001b[1myolov5-container-folds/yolov5-e-7-img-640-fold-22\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 â–ˆâ–…â–„â–â–â–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 â–ˆâ–â–â–‚â–„â–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision â–ˆâ–…â–…â–â–â–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall â–ˆâ–…â–…â–â–â–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss â–ˆâ–…â–…â–ƒâ–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss â–â–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss â–â–ƒâ–„â–ƒâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss â–ˆâ–†â–„â–ƒâ–â–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss â–â–â–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss â–â–ƒâ–„â–†â–ˆâ–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 â–ˆâ–†â–…â–ƒâ–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 â–â–†â–ˆâ–‡â–‚\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 â–â–†â–ˆâ–‡â–‚\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.00013\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 3e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.00025\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.00186\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.00013\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 3e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.00025\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.00186\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.1661\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.00915\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.1762\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.00477\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.06671\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00071\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00071\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run \u001b[33myolov5-e-7-img-640-fold-2\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/oyh5800/yolov5-container-folds/runs/lxsvlflx\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 13 media file(s), 1 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230724_221223-lxsvlflx/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING âš ï¸ wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov5/train.py\", line 647, in <module>\n",
            "    main(opt)\n",
            "  File \"/content/yolov5/train.py\", line 536, in main\n",
            "    train(opt.hyp, opt, device, callbacks)\n",
            "  File \"/content/yolov5/train.py\", line 436, in train\n",
            "    callbacks.run('on_train_end', last, best, epoch, results)\n",
            "  File \"/content/yolov5/utils/callbacks.py\", line 76, in run\n",
            "    logger['callback'](*args, **kwargs)\n",
            "  File \"/content/yolov5/utils/loggers/__init__.py\", line 292, in on_train_end\n",
            "    self.clearml.task.update_output_model(model_path=str(best if best.exists() else last),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/clearml/backend_interface/task/task.py\", line 1011, in update_output_model\n",
            "    output_model.connect(task=self, name=name)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/clearml/model.py\", line 2147, in connect\n",
            "    task.set_model_label_enumeration(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/clearml/task.py\", line 2330, in set_model_label_enumeration\n",
            "    super(Task, self).set_model_label_enumeration(enumeration=enumeration)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/clearml/backend_interface/task/task.py\", line 1399, in set_model_label_enumeration\n",
            "    self._edit(execution=execution)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/clearml/backend_interface/task/task.py\", line 2577, in _edit\n",
            "    res = self.send(tasks.EditRequest(task=self.id, force=True, **kwargs), raise_on_errors=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/clearml/backend_interface/base.py\", line 109, in send\n",
            "    return self._send(session=self.session, req=req, ignore_errors=ignore_errors, raise_on_errors=raise_on_errors,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/clearml/backend_interface/base.py\", line 60, in _send\n",
            "    res = session.send(req, async_enable=async_enable)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/clearml/backend_api/session/session.py\", line 634, in send\n",
            "    res = self.send_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/clearml/backend_api/session/session.py\", line 486, in send_request\n",
            "    return self._send_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/clearml/backend_api/session/session.py\", line 408, in _send_request\n",
            "    res = self.__http_session.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/sessions.py\", line 529, in request\n",
            "    resp = self.send(prep, **send_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/clearml/backend_api/utils.py\", line 85, in send\n",
            "    return super(SessionWithTimeout, self).send(request, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/sessions.py\", line 645, in send\n",
            "    r = adapter.send(request, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/adapters.py\", line 440, in send\n",
            "    resp = conn.urlopen(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 714, in urlopen\n",
            "    httplib_response = self._make_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 466, in _make_request\n",
            "    six.raise_from(e, None)\n",
            "  File \"<string>\", line 3, in raise_from\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 461, in _make_request\n",
            "    httplib_response = conn.getresponse()\n",
            "  File \"/usr/lib/python3.10/http/client.py\", line 1374, in getresponse\n",
            "    response.begin()\n",
            "  File \"/usr/lib/python3.10/http/client.py\", line 318, in begin\n",
            "    version, status, reason = self._read_status()\n",
            "  File \"/usr/lib/python3.10/http/client.py\", line 279, in _read_status\n",
            "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
            "  File \"/usr/lib/python3.10/socket.py\", line 705, in readinto\n",
            "    return self._sock.recv_into(b)\n",
            "  File \"/usr/lib/python3.10/ssl.py\", line 1274, in recv_into\n",
            "    return self.read(nbytes, buffer)\n",
            "  File \"/usr/lib/python3.10/ssl.py\", line 1130, in read\n",
            "    return self._sslobj.read(len, buffer)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/clearml/task.py\", line 4239, in signal_handler\n",
            "    return org_handler if not callable(org_handler) else org_handler(sig, frame)\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "###########################################################################################\n",
            "\n",
            "FOLD NUMBER:  3\n",
            "WARNING âš ï¸ 'ultralytics.yolo.v8' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.models.yolo' instead.\n",
            "WARNING âš ï¸ 'ultralytics.yolo.utils' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.utils' instead.\n",
            "Note this warning may be related to loading older models. You can update your model to current structure with:\n",
            "    import torch\n",
            "    ckpt = torch.load(\"model.pt\")  # applies to both official and custom models\n",
            "    torch.save(ckpt, \"updated-model.pt\")\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING âš ï¸ wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33moyh5800\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=, cfg=/content/yolov5/models/yolov5s.yaml, data=/content/yolov5/data/data_fold_3.yaml, hyp=yolov5/data/hyps/hyp.scratch-low.yaml, epochs=5, batch_size=32, imgsz=256, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5-container-folds, name=yolov5-e-7-img-640-fold-3, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
            "YOLOv5 ğŸš€ v7.0-196-gacdf73b Python-3.10.6 torch-2.0.1+cu118 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 ğŸš€ runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov5-container-folds', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20230724_221405-t82ggx5t\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33myolov5-e-7-img-640-fold-3\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/oyh5800/yolov5-container-folds\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/oyh5800/yolov5-container-folds/runs/t82ggx5t\u001b[0m\n",
            "ClearML Task: created new task id=3564129ad4e049ec89afe9e74ee6f6fd\n",
            "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
            "ClearML results page: https://app.clear.ml/projects/cd2916daae6a43339843d1e80c424e51/experiments/3564129ad4e049ec89afe9e74ee6f6fd/output/log\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "YOLOv5s summary: 214 layers, 7022326 parameters, 7022326 gradients, 15.9 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset_folds_3/train/labels.cache... 218 images, 0 backgrounds, 0 corrupt: 100% 218/218 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB ram): 100% 218/218 [00:00<00:00, 222.58it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset_folds_3/valid/labels.cache... 54 images, 0 backgrounds, 0 corrupt: 100% 54/54 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram): 100% 54/54 [00:00<00:00, 92.49it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m1.15 anchors/target, 0.674 Best Possible Recall (BPR). Anchors are a poor fit to dataset âš ï¸, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mWARNING âš ï¸ Extremely small objects found: 3060 of 9130 labels are <3 pixels in size\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 8999 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.7652: 100% 1000/1000 [00:01<00:00, 902.47it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 0.9980 best possible recall, 6.00 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=256, metric_all=0.382/0.761-mean/best, past_thr=0.506-mean: 3,3, 6,3, 3,6, 6,5, 8,8, 12,5, 12,12, 28,18, 30,70\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone âœ… (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to yolov5-container-folds/yolov5-e-7-img-640-fold-32/labels.jpg... \n",
            "Image sizes 256 train, 256 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1myolov5-container-folds/yolov5-e-7-img-640-fold-32\u001b[0m\n",
            "Starting training for 5 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/4      1.41G     0.1875   0.007135          0        860        256: 100% 7/7 [00:13<00:00,  1.89s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.20it/s]\n",
            "                   all         54       1023   0.000617    0.00978   0.000319   6.54e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/4      1.41G     0.1815   0.007966          0        850        256: 100% 7/7 [00:00<00:00, 12.01it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.09s/it]\n",
            "                   all         54       1023   0.000679     0.0108   0.000379   7.39e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/4      1.41G     0.1788   0.008705          0       1114        256: 100% 7/7 [00:00<00:00, 12.19it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.29it/s]\n",
            "                   all         54       1023   0.000864     0.0137   0.000461   9.17e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/4      1.41G     0.1752   0.009131          0        725        256: 100% 7/7 [00:00<00:00, 11.77it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.10it/s]\n",
            "                   all         54       1023   0.000802     0.0127   0.000417   9.26e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/4      1.41G     0.1717    0.01003          0        736        256: 100% 7/7 [00:00<00:00, 13.18it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.45it/s]\n",
            "                   all         54       1023   0.000802     0.0127   0.000421   9.31e-05\n",
            "\n",
            "5 epochs completed in 0.006 hours.\n",
            "Optimizer stripped from yolov5-container-folds/yolov5-e-7-img-640-fold-32/weights/last.pt, 14.3MB\n",
            "Optimizer stripped from yolov5-container-folds/yolov5-e-7-img-640-fold-32/weights/best.pt, 14.3MB\n",
            "\n",
            "Validating yolov5-container-folds/yolov5-e-7-img-640-fold-32/weights/best.pt...\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.42it/s]\n",
            "                   all         54       1023   0.000864     0.0137   0.000461   9.17e-05\n",
            "Results saved to \u001b[1myolov5-container-folds/yolov5-e-7-img-640-fold-32\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 â–â–„â–ˆâ–†â–†â–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 â–â–ƒâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision â–â–ƒâ–ˆâ–†â–†â–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall â–â–ƒâ–ˆâ–†â–†â–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss â–ˆâ–…â–„â–ƒâ–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss â–â–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss â–â–ƒâ–…â–†â–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss â–ˆâ–†â–„â–‚â–â–„\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss â–â–â–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss â–â–ƒâ–…â–‡â–ˆâ–…\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 â–ˆâ–†â–…â–ƒâ–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 â–â–†â–ˆâ–‡â–‚\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 â–â–†â–ˆâ–‡â–‚\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.00046\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 9e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.00086\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.01369\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.00046\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 9e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.00086\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.01369\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.1717\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.01003\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.17505\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.00456\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.06671\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00071\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00071\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run \u001b[33myolov5-e-7-img-640-fold-3\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/oyh5800/yolov5-container-folds/runs/t82ggx5t\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 13 media file(s), 1 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230724_221405-t82ggx5t/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING âš ï¸ wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
            "###########################################################################################\n",
            "\n",
            "FOLD NUMBER:  4\n",
            "WARNING âš ï¸ 'ultralytics.yolo.v8' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.models.yolo' instead.\n",
            "WARNING âš ï¸ 'ultralytics.yolo.utils' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.utils' instead.\n",
            "Note this warning may be related to loading older models. You can update your model to current structure with:\n",
            "    import torch\n",
            "    ckpt = torch.load(\"model.pt\")  # applies to both official and custom models\n",
            "    torch.save(ckpt, \"updated-model.pt\")\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING âš ï¸ wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33moyh5800\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=, cfg=/content/yolov5/models/yolov5s.yaml, data=/content/yolov5/data/data_fold_4.yaml, hyp=yolov5/data/hyps/hyp.scratch-low.yaml, epochs=5, batch_size=32, imgsz=256, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5-container-folds, name=yolov5-e-7-img-640-fold-4, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
            "YOLOv5 ğŸš€ v7.0-196-gacdf73b Python-3.10.6 torch-2.0.1+cu118 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 ğŸš€ runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov5-container-folds', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20230724_221606-705fv2fk\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33myolov5-e-7-img-640-fold-4\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/oyh5800/yolov5-container-folds\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/oyh5800/yolov5-container-folds/runs/705fv2fk\u001b[0m\n",
            "ClearML Task: created new task id=52c12c204c9e4200bdaf43aca9a52ff0\n",
            "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
            "ClearML results page: https://app.clear.ml/projects/cd2916daae6a43339843d1e80c424e51/experiments/52c12c204c9e4200bdaf43aca9a52ff0/output/log\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "YOLOv5s summary: 214 layers, 7022326 parameters, 7022326 gradients, 15.9 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset_folds_4/train/labels.cache... 218 images, 0 backgrounds, 0 corrupt: 100% 218/218 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB ram): 100% 218/218 [00:01<00:00, 214.96it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset_folds_4/valid/labels.cache... 54 images, 0 backgrounds, 0 corrupt: 100% 54/54 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram): 100% 54/54 [00:00<00:00, 81.00it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m1.09 anchors/target, 0.650 Best Possible Recall (BPR). Anchors are a poor fit to dataset âš ï¸, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mWARNING âš ï¸ Extremely small objects found: 2819 of 7809 labels are <3 pixels in size\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 7680 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.7628: 100% 1000/1000 [00:01<00:00, 942.75it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 0.9983 best possible recall, 5.55 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=256, metric_all=0.355/0.758-mean/best, past_thr=0.496-mean: 3,3, 5,2, 3,6, 5,5, 8,8, 16,5, 13,13, 45,12, 17,72\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone âœ… (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to yolov5-container-folds/yolov5-e-7-img-640-fold-42/labels.jpg... \n",
            "Image sizes 256 train, 256 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1myolov5-container-folds/yolov5-e-7-img-640-fold-42\u001b[0m\n",
            "Starting training for 5 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/4      1.41G     0.1877   0.005809          0        679        256: 100% 7/7 [00:12<00:00,  1.74s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.20it/s]\n",
            "                   all         54       2344    0.00117    0.00811   0.000606   0.000155\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/4      1.41G     0.1824   0.006534          0        820        256: 100% 7/7 [00:00<00:00, 12.29it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.37it/s]\n",
            "                   all         54       2344    0.00142    0.00981   0.000724   0.000167\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/4      1.41G       0.18   0.006867          0        577        256: 100% 7/7 [00:00<00:00, 13.16it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.41it/s]\n",
            "                   all         54       2344    0.00142    0.00981   0.000744   0.000165\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/4      1.41G     0.1759   0.007714          0        738        256: 100% 7/7 [00:00<00:00, 12.41it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.03it/s]\n",
            "                   all         54       2344    0.00148     0.0102   0.000821    0.00017\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/4      1.41G     0.1724   0.007876          0        668        256: 100% 7/7 [00:00<00:00, 12.22it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.20it/s]\n",
            "                   all         54       2344    0.00136    0.00939   0.000699   0.000137\n",
            "\n",
            "5 epochs completed in 0.006 hours.\n",
            "Optimizer stripped from yolov5-container-folds/yolov5-e-7-img-640-fold-42/weights/last.pt, 14.3MB\n",
            "Optimizer stripped from yolov5-container-folds/yolov5-e-7-img-640-fold-42/weights/best.pt, 14.3MB\n",
            "\n",
            "Validating yolov5-container-folds/yolov5-e-7-img-640-fold-42/weights/best.pt...\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.30it/s]\n",
            "                   all         54       2344    0.00148     0.0102   0.000844   0.000172\n",
            "Results saved to \u001b[1myolov5-container-folds/yolov5-e-7-img-640-fold-42\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 â–â–„â–…â–‡â–„â–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 â–…â–‡â–‡â–ˆâ–â–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision â–â–‡â–‡â–ˆâ–…â–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall â–â–‡â–‡â–ˆâ–…â–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss â–ˆâ–†â–„â–ƒâ–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss â–â–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss â–â–ƒâ–…â–‡â–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss â–ˆâ–†â–„â–‚â–â–‚\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss â–â–â–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss â–â–ƒâ–„â–†â–ˆâ–†\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 â–ˆâ–†â–…â–ƒâ–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 â–â–†â–ˆâ–‡â–‚\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 â–â–†â–ˆâ–‡â–‚\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.00082\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.00017\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.00148\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.01024\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.00084\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.00017\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.00148\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.01024\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.17244\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.00788\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.17244\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.00691\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.06671\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00071\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00071\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run \u001b[33myolov5-e-7-img-640-fold-4\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/oyh5800/yolov5-container-folds/runs/705fv2fk\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 12 media file(s), 1 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230724_221606-705fv2fk/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING âš ï¸ wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
            "###########################################################################################\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_WEIGHTS = [\n",
        "    'content/yolov5-container-folds/yolov5s-e-7-img-640-fold-0/weights/best.pt',\n",
        "    'content/yolov5-container-folds/yolov5s-e-7-img-640-fold-1/weights/best.pt',\n",
        "    'content/yolov5-container-folds/yolov5s-e-7-img-640-fold-2/weights/best.pt',\n",
        "    'content/yolov5-container-folds/yolov5s-e-7-img-640-fold-3/weights/best.pt',\n",
        "    'content/yolov5-container-folds/yolov5s-e-7-img-640-fold-4/weights/best.pt',\n",
        "]\n",
        "\n",
        "SOURCES = [\n",
        "    'content/dataset_folds_0/valid/images',\n",
        "    'content/dataset_folds_1/valid/images',\n",
        "    'content/dataset_folds_2/valid/images',\n",
        "    'content/dataset_folds_3/valid/images',\n",
        "    'content/dataset_folds_4/valid/images',\n",
        "]\n",
        "\n",
        "CONFIDENCE = [\n",
        "    0.179, 0.209, 0.268, 0.269, 0.308\n",
        "]"
      ],
      "metadata": {
        "id": "lloGPjYVq7t3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train YOLOv5s on kari on 10 epochs\n",
        "!python /content/yolov5/train.py --img 640  --batch 16 --epochs 7 --data /content/dir1/data.yaml --weights '' --cfg /content/yolov5/models/yolov5s.yaml --cache"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUxzQhhUd-RF",
        "outputId": "f0481c22-28dc-4600-fa3b-ed4347b5ea24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING âš ï¸ 'ultralytics.yolo.v8' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.models.yolo' instead.\n",
            "WARNING âš ï¸ 'ultralytics.yolo.utils' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.utils' instead.\n",
            "Note this warning may be related to loading older models. You can update your model to current structure with:\n",
            "    import torch\n",
            "    ckpt = torch.load(\"model.pt\")  # applies to both official and custom models\n",
            "    torch.save(ckpt, \"updated-model.pt\")\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING âš ï¸ wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33moyh5800\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=, cfg=/content/yolov5/models/yolov5s.yaml, data=/content/dir1/data.yaml, hyp=yolov5/data/hyps/hyp.scratch-low.yaml, epochs=7, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5/runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov5/train.py\", line 647, in <module>\n",
            "    main(opt)\n",
            "  File \"/content/yolov5/train.py\", line 511, in main\n",
            "    check_file(opt.data), check_yaml(opt.cfg), check_yaml(opt.hyp), str(opt.weights), str(opt.project)  # checks\n",
            "  File \"/content/yolov5/utils/general.py\", line 458, in check_file\n",
            "    assert len(files), f'File not found: {file}'  # assert file was found\n",
            "AssertionError: File not found: /content/dir1/data.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "/content/yolov5-container-folds/yolov5-e-7-img-640-fold-2/weights/best.pt"
      ],
      "metadata": {
        "id": "zOc97mIy4UyT",
        "outputId": "3d43ddd4-a74b-48c2-f988-90474d743a74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-63957302daed>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcontent\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0myolov5\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mfolds\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0myolov5\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m640\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'content' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.rmtree('/content/yolov5/runs/detect')"
      ],
      "metadata": {
        "id": "fME-Q3pU6Ny_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for fold in range(1):\n",
        "  print('FOLD NUMBER: ', fold)\n",
        "\n",
        "  !python yolov5/detect.py --weight /content/yolov5-container-folds/yolov5-e-7-img-640-fold-{fold}/weights/best.pt \\\n",
        "  --source /content/temporaryforcolab/test_images \\\n",
        "  --img 640 \\\n",
        "  --save-txt \\\n",
        "  --save-conf\\\n",
        "  --augment\n",
        "  print('###########################################################################################\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVXlYXexwHjP",
        "outputId": "a223b19a-3db8-4a07-84e3-387075341b36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD NUMBER:  0\n",
            "WARNING âš ï¸ 'ultralytics.yolo.v8' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.models.yolo' instead.\n",
            "WARNING âš ï¸ 'ultralytics.yolo.utils' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.utils' instead.\n",
            "Note this warning may be related to loading older models. You can update your model to current structure with:\n",
            "    import torch\n",
            "    ckpt = torch.load(\"model.pt\")  # applies to both official and custom models\n",
            "    torch.save(ckpt, \"updated-model.pt\")\n",
            "\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/yolov5-container-folds/yolov5-e-7-img-640-fold-0/weights/best.pt'], source=/content/temporaryforcolab/test_images, data=yolov5/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_conf=True, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=True, visualize=False, update=False, project=yolov5/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 ğŸš€ v7.0-196-gacdf73b Python-3.10.6 torch-2.0.1+cu118 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "image 1/177 /content/temporaryforcolab/test_images/OBJ00607_PS3_K3_NIA0086.png: 640x640 (no detections), 200.1ms\n",
            "image 2/177 /content/temporaryforcolab/test_images/OBJ01347_PS3_K3_NIA0092.png: 640x640 (no detections), 18.7ms\n",
            "image 3/177 /content/temporaryforcolab/test_images/OBJ01357_PS3_K3_NIA0092.png: 640x640 (no detections), 18.3ms\n",
            "image 4/177 /content/temporaryforcolab/test_images/OBJ01527_PS3_K3_NIA0095.png: 640x640 (no detections), 18.9ms\n",
            "image 5/177 /content/temporaryforcolab/test_images/OBJ01675_PS3_K3_NIA0102.png: 640x640 (no detections), 19.5ms\n",
            "image 6/177 /content/temporaryforcolab/test_images/OBJ01701_PS3_K3_NIA0102.png: 640x640 (no detections), 18.5ms\n",
            "image 7/177 /content/temporaryforcolab/test_images/OBJ01925_PS3_K3_NIA0110.png: 640x640 (no detections), 18.8ms\n",
            "image 8/177 /content/temporaryforcolab/test_images/OBJ02240_PS3_K3_NIA0117.png: 640x640 (no detections), 18.1ms\n",
            "image 9/177 /content/temporaryforcolab/test_images/OBJ02477_PS3_K3_NIA0123.png: 640x640 (no detections), 18.7ms\n",
            "image 10/177 /content/temporaryforcolab/test_images/OBJ02546_PS3_K3_NIA0124.png: 640x640 (no detections), 19.3ms\n",
            "image 11/177 /content/temporaryforcolab/test_images/OBJ03321_PS3_K3A_NIA0137.png: 640x640 (no detections), 18.3ms\n",
            "image 12/177 /content/temporaryforcolab/test_images/OBJ03368_PS3_K3A_NIA0137.png: 640x640 (no detections), 18.4ms\n",
            "image 13/177 /content/temporaryforcolab/test_images/OBJ03369_PS3_K3A_NIA0137.png: 640x640 (no detections), 18.5ms\n",
            "image 14/177 /content/temporaryforcolab/test_images/OBJ03391_PS3_K3A_NIA0137.png: 640x640 (no detections), 18.4ms\n",
            "image 15/177 /content/temporaryforcolab/test_images/OBJ03424_PS3_K3A_NIA0139.png: 640x640 (no detections), 18.7ms\n",
            "image 16/177 /content/temporaryforcolab/test_images/OBJ03425_PS3_K3A_NIA0139.png: 640x640 (no detections), 18.5ms\n",
            "image 17/177 /content/temporaryforcolab/test_images/OBJ03426_PS3_K3A_NIA0139.png: 640x640 (no detections), 18.1ms\n",
            "image 18/177 /content/temporaryforcolab/test_images/OBJ03445_PS3_K3A_NIA0139.png: 640x640 (no detections), 18.7ms\n",
            "image 19/177 /content/temporaryforcolab/test_images/OBJ03477_PS3_K3A_NIA0142.png: 640x640 (no detections), 18.2ms\n",
            "image 20/177 /content/temporaryforcolab/test_images/OBJ03481_PS3_K3A_NIA0143.png: 640x640 (no detections), 18.3ms\n",
            "image 21/177 /content/temporaryforcolab/test_images/OBJ03540_PS3_K3A_NIA0148.png: 640x640 (no detections), 18.4ms\n",
            "image 22/177 /content/temporaryforcolab/test_images/OBJ03563_PS3_K3A_NIA0150.png: 640x640 (no detections), 18.3ms\n",
            "image 23/177 /content/temporaryforcolab/test_images/OBJ03570_PS3_K3A_NIA0150.png: 640x640 (no detections), 18.1ms\n",
            "image 24/177 /content/temporaryforcolab/test_images/OBJ03572_PS3_K3A_NIA0150.png: 640x640 (no detections), 18.6ms\n",
            "image 25/177 /content/temporaryforcolab/test_images/OBJ03579_PS3_K3A_NIA0151.png: 640x640 (no detections), 18.6ms\n",
            "image 26/177 /content/temporaryforcolab/test_images/OBJ03594_PS3_K3A_NIA0151.png: 640x640 (no detections), 18.8ms\n",
            "image 27/177 /content/temporaryforcolab/test_images/OBJ03597_PS3_K3A_NIA0151.png: 640x640 (no detections), 18.6ms\n",
            "image 28/177 /content/temporaryforcolab/test_images/OBJ03612_PS3_K3A_NIA0151.png: 640x640 (no detections), 18.3ms\n",
            "image 29/177 /content/temporaryforcolab/test_images/OBJ03614_PS3_K3A_NIA0151.png: 640x640 (no detections), 18.7ms\n",
            "image 30/177 /content/temporaryforcolab/test_images/OBJ03644_PS3_K3A_NIA0152.png: 640x640 (no detections), 18.8ms\n",
            "image 31/177 /content/temporaryforcolab/test_images/OBJ03649_PS3_K3A_NIA0153.png: 640x640 (no detections), 18.6ms\n",
            "image 32/177 /content/temporaryforcolab/test_images/OBJ03653_PS3_K3A_NIA0153.png: 640x640 (no detections), 18.7ms\n",
            "image 33/177 /content/temporaryforcolab/test_images/OBJ03687_PS3_K3A_NIA0154.png: 640x640 (no detections), 18.5ms\n",
            "image 34/177 /content/temporaryforcolab/test_images/OBJ03722_PS3_K3A_NIA0156.png: 640x640 (no detections), 18.6ms\n",
            "image 35/177 /content/temporaryforcolab/test_images/OBJ03786_PS3_K3A_NIA0158.png: 640x640 (no detections), 18.9ms\n",
            "image 36/177 /content/temporaryforcolab/test_images/OBJ03787_PS3_K3A_NIA0158.png: 640x640 (no detections), 18.6ms\n",
            "image 37/177 /content/temporaryforcolab/test_images/OBJ03809_PS3_K3A_NIA0159.png: 640x640 (no detections), 18.8ms\n",
            "image 38/177 /content/temporaryforcolab/test_images/OBJ03892_PS3_K3A_NIA0164.png: 640x640 (no detections), 18.4ms\n",
            "image 39/177 /content/temporaryforcolab/test_images/OBJ03896_PS3_K3A_NIA0164.png: 640x640 (no detections), 19.0ms\n",
            "image 40/177 /content/temporaryforcolab/test_images/OBJ03911_PS3_K3A_NIA0165.png: 640x640 (no detections), 18.8ms\n",
            "image 41/177 /content/temporaryforcolab/test_images/OBJ03942_PS3_K3A_NIA0166.png: 640x640 (no detections), 18.6ms\n",
            "image 42/177 /content/temporaryforcolab/test_images/OBJ03948_PS3_K3A_NIA0166.png: 640x640 (no detections), 18.6ms\n",
            "image 43/177 /content/temporaryforcolab/test_images/OBJ03951_PS3_K3A_NIA0166.png: 640x640 (no detections), 18.6ms\n",
            "image 44/177 /content/temporaryforcolab/test_images/OBJ03952_PS3_K3A_NIA0166.png: 640x640 (no detections), 18.8ms\n",
            "image 45/177 /content/temporaryforcolab/test_images/OBJ03962_PS3_K3A_NIA0166.png: 640x640 (no detections), 18.5ms\n",
            "image 46/177 /content/temporaryforcolab/test_images/OBJ03965_PS3_K3A_NIA0166.png: 640x640 (no detections), 18.4ms\n",
            "image 47/177 /content/temporaryforcolab/test_images/OBJ03972_PS3_K3A_NIA0166.png: 640x640 (no detections), 18.4ms\n",
            "image 48/177 /content/temporaryforcolab/test_images/OBJ03976_PS3_K3A_NIA0166.png: 640x640 (no detections), 18.3ms\n",
            "image 49/177 /content/temporaryforcolab/test_images/OBJ03983_PS3_K3A_NIA0166.png: 640x640 (no detections), 18.4ms\n",
            "image 50/177 /content/temporaryforcolab/test_images/OBJ03984_PS3_K3A_NIA0166.png: 640x640 (no detections), 18.4ms\n",
            "image 51/177 /content/temporaryforcolab/test_images/OBJ03985_PS3_K3A_NIA0166.png: 640x640 (no detections), 18.7ms\n",
            "image 52/177 /content/temporaryforcolab/test_images/OBJ04000_PS3_K3A_NIA0167.png: 640x640 (no detections), 18.9ms\n",
            "image 53/177 /content/temporaryforcolab/test_images/OBJ04011_PS3_K3A_NIA0167.png: 640x640 (no detections), 18.8ms\n",
            "image 54/177 /content/temporaryforcolab/test_images/OBJ04024_PS3_K3A_NIA0169.png: 640x640 (no detections), 19.2ms\n",
            "image 55/177 /content/temporaryforcolab/test_images/OBJ04031_PS3_K3A_NIA0169.png: 640x640 (no detections), 18.6ms\n",
            "image 56/177 /content/temporaryforcolab/test_images/OBJ04032_PS3_K3A_NIA0169.png: 640x640 (no detections), 18.5ms\n",
            "image 57/177 /content/temporaryforcolab/test_images/OBJ04100_PS3_K3A_NIA0174.png: 640x640 (no detections), 18.4ms\n",
            "image 58/177 /content/temporaryforcolab/test_images/OBJ04116_PS3_K3A_NIA0175.png: 640x640 (no detections), 18.3ms\n",
            "image 59/177 /content/temporaryforcolab/test_images/OBJ04118_PS3_K3A_NIA0175.png: 640x640 (no detections), 18.5ms\n",
            "image 60/177 /content/temporaryforcolab/test_images/OBJ04126_PS3_K3A_NIA0176.png: 640x640 (no detections), 18.0ms\n",
            "image 61/177 /content/temporaryforcolab/test_images/OBJ04129_PS3_K3A_NIA0176.png: 640x640 (no detections), 18.0ms\n",
            "image 62/177 /content/temporaryforcolab/test_images/OBJ04130_PS3_K3A_NIA0176.png: 640x640 (no detections), 18.1ms\n",
            "image 63/177 /content/temporaryforcolab/test_images/OBJ04136_PS3_K3A_NIA0177.png: 640x640 (no detections), 18.4ms\n",
            "image 64/177 /content/temporaryforcolab/test_images/OBJ04141_PS3_K3A_NIA0178.png: 640x640 (no detections), 18.4ms\n",
            "image 65/177 /content/temporaryforcolab/test_images/OBJ04148_PS3_K3A_NIA0179.png: 640x640 (no detections), 19.1ms\n",
            "image 66/177 /content/temporaryforcolab/test_images/OBJ04168_PS3_K3A_NIA0180.png: 640x640 (no detections), 18.2ms\n",
            "image 67/177 /content/temporaryforcolab/test_images/OBJ04178_PS3_K3A_NIA0180.png: 640x640 (no detections), 18.7ms\n",
            "image 68/177 /content/temporaryforcolab/test_images/OBJ04189_PS3_K3A_NIA0181.png: 640x640 (no detections), 18.5ms\n",
            "image 69/177 /content/temporaryforcolab/test_images/OBJ04337_PS3_K3A_NIA0282.png: 640x640 (no detections), 19.2ms\n",
            "image 70/177 /content/temporaryforcolab/test_images/OBJ04338_PS3_K3A_NIA0282.png: 640x640 (no detections), 20.1ms\n",
            "image 71/177 /content/temporaryforcolab/test_images/OBJ04348_PS3_K3A_NIA0283.png: 640x640 (no detections), 18.5ms\n",
            "image 72/177 /content/temporaryforcolab/test_images/OBJ04366_PS3_K3A_NIA0285.png: 640x640 (no detections), 18.8ms\n",
            "image 73/177 /content/temporaryforcolab/test_images/OBJ04403_PS3_K3A_NIA0289.png: 640x640 (no detections), 18.7ms\n",
            "image 74/177 /content/temporaryforcolab/test_images/OBJ04410_PS3_K3A_NIA0289.png: 640x640 (no detections), 18.4ms\n",
            "image 75/177 /content/temporaryforcolab/test_images/OBJ04413_PS3_K3A_NIA0289.png: 640x640 (no detections), 18.8ms\n",
            "image 76/177 /content/temporaryforcolab/test_images/OBJ04421_PS3_K3A_NIA0290.png: 640x640 (no detections), 19.0ms\n",
            "image 77/177 /content/temporaryforcolab/test_images/OBJ04444_PS3_K3A_NIA0292.png: 640x640 (no detections), 18.4ms\n",
            "image 78/177 /content/temporaryforcolab/test_images/OBJ04448_PS3_K3A_NIA0292.png: 640x640 (no detections), 18.5ms\n",
            "image 79/177 /content/temporaryforcolab/test_images/OBJ04461_PS3_K3A_NIA0293.png: 640x640 (no detections), 18.8ms\n",
            "image 80/177 /content/temporaryforcolab/test_images/OBJ04464_PS3_K3A_NIA0293.png: 640x640 (no detections), 18.9ms\n",
            "image 81/177 /content/temporaryforcolab/test_images/OBJ04479_PS3_K3A_NIA0294.png: 640x640 (no detections), 18.7ms\n",
            "image 82/177 /content/temporaryforcolab/test_images/OBJ04480_PS3_K3A_NIA0294.png: 640x640 (no detections), 18.7ms\n",
            "image 83/177 /content/temporaryforcolab/test_images/OBJ04521_PS3_K3A_NIA0299.png: 640x640 (no detections), 18.5ms\n",
            "image 84/177 /content/temporaryforcolab/test_images/OBJ04539_PS3_K3A_NIA0300.png: 640x640 (no detections), 18.9ms\n",
            "image 85/177 /content/temporaryforcolab/test_images/OBJ04556_PS3_K3A_NIA0300.png: 640x640 (no detections), 18.6ms\n",
            "image 86/177 /content/temporaryforcolab/test_images/OBJ04572_PS3_K3A_NIA0301.png: 640x640 (no detections), 18.8ms\n",
            "image 87/177 /content/temporaryforcolab/test_images/OBJ04599_PS3_K3A_NIA0302.png: 640x640 (no detections), 18.7ms\n",
            "image 88/177 /content/temporaryforcolab/test_images/OBJ04601_PS3_K3A_NIA0303.png: 640x640 (no detections), 18.5ms\n",
            "image 89/177 /content/temporaryforcolab/test_images/OBJ04629_PS3_K3A_NIA0304.png: 640x640 (no detections), 18.8ms\n",
            "image 90/177 /content/temporaryforcolab/test_images/OBJ04641_PS3_K3A_NIA0305.png: 640x640 (no detections), 18.7ms\n",
            "image 91/177 /content/temporaryforcolab/test_images/OBJ04643_PS3_K3A_NIA0306.png: 640x640 (no detections), 18.5ms\n",
            "image 92/177 /content/temporaryforcolab/test_images/OBJ04650_PS3_K3A_NIA0308.png: 640x640 (no detections), 18.5ms\n",
            "image 93/177 /content/temporaryforcolab/test_images/OBJ04652_PS3_K3A_NIA0308.png: 640x640 (no detections), 18.4ms\n",
            "image 94/177 /content/temporaryforcolab/test_images/OBJ04667_PS3_K3A_NIA0311.png: 640x640 (no detections), 18.2ms\n",
            "image 95/177 /content/temporaryforcolab/test_images/OBJ04692_PS3_K3A_NIA0312.png: 640x640 (no detections), 18.9ms\n",
            "image 96/177 /content/temporaryforcolab/test_images/OBJ04737_PS3_K3A_NIA0314.png: 640x640 (no detections), 18.4ms\n",
            "image 97/177 /content/temporaryforcolab/test_images/OBJ04754_PS3_K3A_NIA0314.png: 640x640 (no detections), 18.3ms\n",
            "image 98/177 /content/temporaryforcolab/test_images/OBJ04778_PS3_K3A_NIA0297.png: 640x640 (no detections), 19.1ms\n",
            "image 99/177 /content/temporaryforcolab/test_images/OBJ04786_PS3_K3A_NIA0297.png: 640x640 (no detections), 18.5ms\n",
            "image 100/177 /content/temporaryforcolab/test_images/OBJ04805_PS3_K3A_NIA0315.png: 640x640 (no detections), 18.5ms\n",
            "image 101/177 /content/temporaryforcolab/test_images/OBJ04807_PS3_K3A_NIA0315.png: 640x640 (no detections), 18.5ms\n",
            "image 102/177 /content/temporaryforcolab/test_images/OBJ04812_PS3_K3A_NIA0315.png: 640x640 (no detections), 18.3ms\n",
            "image 103/177 /content/temporaryforcolab/test_images/OBJ04814_PS3_K3A_NIA0315.png: 640x640 (no detections), 18.3ms\n",
            "image 104/177 /content/temporaryforcolab/test_images/OBJ04815_PS3_K3A_NIA0315.png: 640x640 (no detections), 18.4ms\n",
            "image 105/177 /content/temporaryforcolab/test_images/OBJ04816_PS3_K3A_NIA0315.png: 640x640 (no detections), 18.9ms\n",
            "image 106/177 /content/temporaryforcolab/test_images/OBJ04818_PS3_K3A_NIA0316.png: 640x640 (no detections), 18.6ms\n",
            "image 107/177 /content/temporaryforcolab/test_images/OBJ04824_PS3_K3A_NIA0316.png: 640x640 (no detections), 18.5ms\n",
            "image 108/177 /content/temporaryforcolab/test_images/OBJ04864_PS3_K3A_NIA0318.png: 640x640 (no detections), 18.4ms\n",
            "image 109/177 /content/temporaryforcolab/test_images/OBJ04871_PS3_K3A_NIA0318.png: 640x640 (no detections), 18.3ms\n",
            "image 110/177 /content/temporaryforcolab/test_images/OBJ04879_PS3_K3A_NIA0318.png: 640x640 (no detections), 19.2ms\n",
            "image 111/177 /content/temporaryforcolab/test_images/OBJ04884_PS3_K3A_NIA0319.png: 640x640 (no detections), 18.3ms\n",
            "image 112/177 /content/temporaryforcolab/test_images/OBJ04909_PS3_K3A_NIA0322.png: 640x640 (no detections), 18.1ms\n",
            "image 113/177 /content/temporaryforcolab/test_images/OBJ04931_PS3_K3A_NIA0172.png: 640x640 (no detections), 18.4ms\n",
            "image 114/177 /content/temporaryforcolab/test_images/OBJ04939_PS3_K3A_NIA0324.png: 640x640 (no detections), 18.8ms\n",
            "image 115/177 /content/temporaryforcolab/test_images/OBJ04940_PS3_K3A_NIA0324.png: 640x640 (no detections), 19.0ms\n",
            "image 116/177 /content/temporaryforcolab/test_images/OBJ04959_PS3_K3A_NIA0326.png: 640x640 (no detections), 18.6ms\n",
            "image 117/177 /content/temporaryforcolab/test_images/OBJ04999_PS3_K3A_NIA0328.png: 640x640 (no detections), 18.4ms\n",
            "image 118/177 /content/temporaryforcolab/test_images/OBJ05004_PS3_K3A_NIA0328.png: 640x640 (no detections), 18.8ms\n",
            "image 119/177 /content/temporaryforcolab/test_images/OBJ05040_PS3_K3A_NIA0329.png: 640x640 (no detections), 18.2ms\n",
            "image 120/177 /content/temporaryforcolab/test_images/OBJ05053_PS3_K3A_NIA0329.png: 640x640 (no detections), 18.4ms\n",
            "image 121/177 /content/temporaryforcolab/test_images/OBJ05068_PS3_K3A_NIA0330.png: 640x640 (no detections), 19.6ms\n",
            "image 122/177 /content/temporaryforcolab/test_images/OBJ05073_PS3_K3A_NIA0331.png: 640x640 (no detections), 18.3ms\n",
            "image 123/177 /content/temporaryforcolab/test_images/OBJ05086_PS3_K3A_NIA0332.png: 640x640 (no detections), 18.9ms\n",
            "image 124/177 /content/temporaryforcolab/test_images/OBJ05103_PS3_K3A_NIA0333.png: 640x640 (no detections), 18.6ms\n",
            "image 125/177 /content/temporaryforcolab/test_images/OBJ05117_PS3_K3A_NIA0333.png: 640x640 (no detections), 18.6ms\n",
            "image 126/177 /content/temporaryforcolab/test_images/OBJ05133_PS3_K3A_NIA0334.png: 640x640 (no detections), 18.2ms\n",
            "image 127/177 /content/temporaryforcolab/test_images/OBJ05134_PS3_K3A_NIA0334.png: 640x640 (no detections), 18.3ms\n",
            "image 128/177 /content/temporaryforcolab/test_images/OBJ05149_PS3_K3A_NIA0335.png: 640x640 (no detections), 18.4ms\n",
            "image 129/177 /content/temporaryforcolab/test_images/OBJ05153_PS3_K3A_NIA0336.png: 640x640 (no detections), 18.3ms\n",
            "image 130/177 /content/temporaryforcolab/test_images/OBJ05188_PS3_K3A_NIA0340.png: 640x640 (no detections), 18.3ms\n",
            "image 131/177 /content/temporaryforcolab/test_images/OBJ05207_PS3_K3A_NIA0340.png: 640x640 (no detections), 18.5ms\n",
            "image 132/177 /content/temporaryforcolab/test_images/OBJ05213_PS3_K3A_NIA0340.png: 640x640 (no detections), 18.4ms\n",
            "image 133/177 /content/temporaryforcolab/test_images/OBJ05214_PS3_K3A_NIA0340.png: 640x640 (no detections), 19.0ms\n",
            "image 134/177 /content/temporaryforcolab/test_images/OBJ05222_PS3_K3A_NIA0341.png: 640x640 (no detections), 18.2ms\n",
            "image 135/177 /content/temporaryforcolab/test_images/OBJ05254_PS3_K3A_NIA0341.png: 640x640 (no detections), 18.5ms\n",
            "image 136/177 /content/temporaryforcolab/test_images/OBJ05286_PS3_K3A_NIA0342.png: 640x640 (no detections), 18.6ms\n",
            "image 137/177 /content/temporaryforcolab/test_images/OBJ05288_PS3_K3A_NIA0342.png: 640x640 (no detections), 18.6ms\n",
            "image 138/177 /content/temporaryforcolab/test_images/OBJ05300_PS3_K3A_NIA0344.png: 640x640 (no detections), 18.4ms\n",
            "image 139/177 /content/temporaryforcolab/test_images/OBJ05307_PS3_K3A_NIA0344.png: 640x640 (no detections), 18.6ms\n",
            "image 140/177 /content/temporaryforcolab/test_images/OBJ05313_PS3_K3A_NIA0344.png: 640x640 (no detections), 18.2ms\n",
            "image 141/177 /content/temporaryforcolab/test_images/OBJ05326_PS3_K3A_NIA0345.png: 640x640 (no detections), 19.0ms\n",
            "image 142/177 /content/temporaryforcolab/test_images/OBJ05347_PS3_K3A_NIA0345.png: 640x640 (no detections), 18.3ms\n",
            "image 143/177 /content/temporaryforcolab/test_images/OBJ05364_PS3_K3A_NIA0346.png: 640x640 (no detections), 18.4ms\n",
            "image 144/177 /content/temporaryforcolab/test_images/OBJ05375_PS3_K3A_NIA0346.png: 640x640 (no detections), 18.3ms\n",
            "image 145/177 /content/temporaryforcolab/test_images/OBJ05382_PS3_K3A_NIA0346.png: 640x640 (no detections), 18.4ms\n",
            "image 146/177 /content/temporaryforcolab/test_images/OBJ05397_PS3_K3A_NIA0347.png: 640x640 (no detections), 18.3ms\n",
            "image 147/177 /content/temporaryforcolab/test_images/OBJ05417_PS3_K3A_NIA0349.png: 640x640 (no detections), 18.5ms\n",
            "image 148/177 /content/temporaryforcolab/test_images/OBJ05423_PS3_K3A_NIA0349.png: 640x640 (no detections), 18.6ms\n",
            "image 149/177 /content/temporaryforcolab/test_images/OBJ05424_PS3_K3A_NIA0349.png: 640x640 (no detections), 18.6ms\n",
            "image 150/177 /content/temporaryforcolab/test_images/OBJ05428_PS3_K3A_NIA0350.png: 640x640 (no detections), 18.7ms\n",
            "image 151/177 /content/temporaryforcolab/test_images/OBJ05429_PS3_K3A_NIA0350.png: 640x640 (no detections), 18.5ms\n",
            "image 152/177 /content/temporaryforcolab/test_images/OBJ05464_PS3_K3A_NIA0166.png: 640x640 (no detections), 18.5ms\n",
            "image 153/177 /content/temporaryforcolab/test_images/OBJ05465_PS3_K3A_NIA0166.png: 640x640 (no detections), 18.4ms\n",
            "image 154/177 /content/temporaryforcolab/test_images/OBJ05474_PS3_K3A_NIA0166.png: 640x640 (no detections), 18.3ms\n",
            "image 155/177 /content/temporaryforcolab/test_images/OBJ05475_PS3_K3A_NIA0166.png: 640x640 (no detections), 18.6ms\n",
            "image 156/177 /content/temporaryforcolab/test_images/OBJ05502_PS3_K3A_NIA0166.png: 640x640 (no detections), 19.1ms\n",
            "image 157/177 /content/temporaryforcolab/test_images/OBJ05504_PS3_K3A_NIA0166.png: 640x640 (no detections), 18.5ms\n",
            "image 158/177 /content/temporaryforcolab/test_images/OBJ05508_PS3_K3A_NIA0166.png: 640x640 (no detections), 18.6ms\n",
            "image 159/177 /content/temporaryforcolab/test_images/OBJ05518_PS3_K3A_NIA0352.png: 640x640 (no detections), 18.4ms\n",
            "image 160/177 /content/temporaryforcolab/test_images/OBJ05524_PS3_K3A_NIA0352.png: 640x640 (no detections), 18.4ms\n",
            "image 161/177 /content/temporaryforcolab/test_images/OBJ05544_PS3_K3A_NIA0354.png: 640x640 (no detections), 18.5ms\n",
            "image 162/177 /content/temporaryforcolab/test_images/OBJ05549_PS3_K3A_NIA0354.png: 640x640 (no detections), 18.6ms\n",
            "image 163/177 /content/temporaryforcolab/test_images/OBJ05575_PS3_K3A_NIA0355.png: 640x640 (no detections), 18.4ms\n",
            "image 164/177 /content/temporaryforcolab/test_images/OBJ05594_PS3_K3A_NIA0357.png: 640x640 (no detections), 18.5ms\n",
            "image 165/177 /content/temporaryforcolab/test_images/OBJ05611_PS3_K3A_NIA0357.png: 640x640 (no detections), 18.7ms\n",
            "image 166/177 /content/temporaryforcolab/test_images/OBJ05629_PS3_K3A_NIA0358.png: 640x640 (no detections), 18.7ms\n",
            "image 167/177 /content/temporaryforcolab/test_images/OBJ05645_PS3_K3A_NIA0359.png: 640x640 (no detections), 18.5ms\n",
            "image 168/177 /content/temporaryforcolab/test_images/OBJ05646_PS3_K3A_NIA0359.png: 640x640 (no detections), 18.5ms\n",
            "image 169/177 /content/temporaryforcolab/test_images/OBJ05651_PS3_K3A_NIA0359.png: 640x640 (no detections), 19.2ms\n",
            "image 170/177 /content/temporaryforcolab/test_images/OBJ05724_PS3_K3A_NIA0363.png: 640x640 (no detections), 18.6ms\n",
            "image 171/177 /content/temporaryforcolab/test_images/OBJ05727_PS3_K3A_NIA0363.png: 640x640 (no detections), 18.8ms\n",
            "image 172/177 /content/temporaryforcolab/test_images/OBJ05747_PS3_K3A_NIA0364.png: 640x640 (no detections), 27.5ms\n",
            "image 173/177 /content/temporaryforcolab/test_images/OBJ05827_PS3_K3A_NIA0595.png: 640x640 (no detections), 18.6ms\n",
            "image 174/177 /content/temporaryforcolab/test_images/OBJ05836_PS3_K3A_NIA0598.png: 640x640 (no detections), 19.4ms\n",
            "image 175/177 /content/temporaryforcolab/test_images/OBJ05840_PS3_K3_NIA0600.png: 640x640 (no detections), 18.6ms\n",
            "image 176/177 /content/temporaryforcolab/test_images/OBJ06535_PS3_K3_NIA0689.png: 640x640 (no detections), 18.5ms\n",
            "image 177/177 /content/temporaryforcolab/test_images/OBJ07401_PS3_K3A_NIA0817.png: 640x640 (no detections), 18.5ms\n",
            "Speed: 0.6ms pre-process, 19.7ms inference, 0.3ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1myolov5/runs/detect/exp\u001b[0m\n",
            "0 labels saved to yolov5/runs/detect/exp/labels\n",
            "###########################################################################################\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ensemble-boxes"
      ],
      "metadata": {
        "id": "kGlkwPTo0FZ5",
        "outputId": "9f9a3e7c-3179-4f99-ff52-1d91d2f63824",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ensemble-boxes\n",
            "  Downloading ensemble_boxes-1.0.9-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ensemble-boxes) (1.22.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from ensemble-boxes) (1.5.3)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from ensemble-boxes) (0.56.4)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->ensemble-boxes) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba->ensemble-boxes) (67.7.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ensemble-boxes) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ensemble-boxes) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->ensemble-boxes) (1.16.0)\n",
            "Installing collected packages: ensemble-boxes\n",
            "Successfully installed ensemble-boxes-1.0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import pandas as pd\n",
        "import os\n",
        "def yolo_to_x1y1x2y2x3y3x4y4(yolo_coords):\n",
        "    \"\"\"\n",
        "    YOLO í˜•ì‹ì˜ bounding box ì¢Œí‘œë¥¼ x1, y1, x2, y2, x3, y3, x4, y4 í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜\n",
        "    \"\"\"\n",
        "    x, y, w, h = yolo_coords\n",
        "    x1, y1 = x - w/2, y - h/2\n",
        "    x2, y2 = x + w/2, y - h/2\n",
        "    x3, y3 = x - w/2, y + h/2\n",
        "    x4, y4 = x + w/2, y + h/2\n",
        "    return x1, y1, x2, y2, x3, y3, x4, y4"
      ],
      "metadata": {
        "id": "4keR65Fl0lfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python content/detect.py --source ../../data/data_splited/data_yolo/images/test --save-txt --save-conf --weight ../../ckpts/yolov5x-endoscopy/endoscopy/weights/best.pt --imgsz 576 --device 0 --augment\n"
      ],
      "metadata": {
        "id": "Ud3jeBBO2FAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Load a model\n",
        "    model = YOLO('/content/yolov5-container-folds/yolov5-e-7-img-640-fold-0/weights/best.pt')\n",
        "    results = model.predict(source='/content/temporaryforcolab/test_images', save=True, save_txt=True)\n",
        "\n",
        "    data = []\n",
        "    for result in results:\n",
        "        boxes = result.boxes.cpu().numpy()\n",
        "        for box in boxes:\n",
        "            file_name = os.path.splitext(os.path.basename(result.path))[0][:8]\n",
        "            conf = box.conf[0]\n",
        "            x1, y1, x2, y2, x3, y3, x4, y4 = yolo_to_x1y1x2y2x3y3x4y4(box.xywh[0])\n",
        "            data.append([file_name, conf, x1, y1, x2, y2, x3, y3, x4, y4])\n",
        "\n",
        "    df = pd.DataFrame(data, columns=['File', 'Confidence', 'X1', 'Y1', 'X2', 'Y2', 'X3', 'Y3', 'X4', 'Y4'])\n",
        "    df.to_csv('content/results/submission1.csv', index=False)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "7hhpevrKCP8Q",
        "outputId": "5a131e15-9af7-47a8-842e-eba38c231f27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mtorch_safe_load\u001b[0;34m(weight)\u001b[0m\n\u001b[1;32m    560\u001b[0m                 'ultralytics.yolo.data': 'ultralytics.data'}):  # for legacy 8.0 Classify and Pose models\n\u001b[0;32m--> 561\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m  \u001b[0;31m# load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    808\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUNSAFE_MESSAGE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    810\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1172\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mfind_class\u001b[0;34m(self, mod_name, name)\u001b[0m\n\u001b[1;32m   1164\u001b[0m             \u001b[0mmod_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_module_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1165\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'models'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-3b06b480a724>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-67-3b06b480a724>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Load a model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/yolov5-container-folds/yolov5-e-7-img-640-fold-0/weights/best.pt'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pretrained YOLOv8n model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/temporaryforcolab/test_images'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_txt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, task)\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(self, weights, task)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0msuffix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msuffix\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'.pt'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mckpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattempt_load_one_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'task'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverrides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset_ckpt_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mattempt_load_one_weight\u001b[0;34m(weight, device, inplace, fuse)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mattempt_load_one_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m     \u001b[0;34m\"\"\"Loads a single model weights.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m     \u001b[0mckpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch_safe_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# load ckpt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mDEFAULT_CFG_DICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_args'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m  \u001b[0;31m# combine model and default args, preferring model args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ema'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mckpt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# FP32 model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mtorch_safe_load\u001b[0;34m(weight)\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# e.name is missing module name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'models'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m             raise TypeError(\n\u001b[0m\u001b[1;32m    566\u001b[0m                 emojis(f'ERROR âŒï¸ {weight} appears to be an Ultralytics YOLOv5 model originally trained '\n\u001b[1;32m    567\u001b[0m                        \u001b[0;34mf'with https://github.com/ultralytics/yolov5.\\nThis model is NOT forwards compatible with '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: ERROR âŒï¸ /content/yolov5-container-folds/yolov5-e-7-img-640-fold-0/weights/best.pt appears to be an Ultralytics YOLOv5 model originally trained with https://github.com/ultralytics/yolov5.\nThis model is NOT forwards compatible with YOLOv8 at https://github.com/ultralytics/ultralytics.\nRecommend fixes are to train a new model using the latest 'ultralytics' package or to run a command with an official YOLOv8 model, i.e. 'yolo predict model=yolov8n.pt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for fold in range(NUM_FOLD):\n",
        "  print('FOLD NUMBER: ', fold)\n",
        "\n",
        "  !python yolov5/detect.py --weights {MODEL_WEIGHTS[fold]} \\"
      ],
      "metadata": {
        "id": "6qRs9k_v0ehl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}